<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
        "http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
	<title>Types Don't Know #</title>

	<style>
	p {text-align:justify}
	li {text-align:justify}
	blockquote.note
	{
		background-color:#E0E0E0;
		padding-left: 15px;
		padding-right: 15px;
		padding-top: 1px;
		padding-bottom: 1px;
	}
	ins {color:#00A000}
	del {color:#A00000}
	</style>
</head>
<body>

<address align=right>
<br/>
<br/>
<a href="mailto:howard.hinnant@gmail.com">Howard E. Hinnant</a><br/>
<a href="mailto:vinnie.falco@gmail.com">Vinnie Falco</a><br/>
2014-04-13
</address>
<hr/>
<h1 align=center>Types Don't Know #</h1>

<h2>Contents</h2>

<ul>
<li><a href="#Introduction">Introduction</a></li>
<li><a href="#Example">The Example</a></li>
<li><a href="#Solution1">Solution 1: Specialize <code>std::hash&lt;X&gt;</code></a>
    <ul>
    <li><a href="#Solution1B">What about implementing it with N3333?</a></li>
    <li><a href="#Solution1C">What about implementing it only with C++14 tools?</a></li>
    </ul>
</li>
<li><a href="#Solution2">Solution 2: Make use of a well-known hashing algorithm</a></li>
<li><a href="#generalpurpose">How to get X to use a general purpose hashing algorithm</a>
    <ul>
    <li><a href="#Universal">Introducing the Universal hash function!</a></li>
    <li><a href="#hash_append">What is <code>hash_append</code>?</a>
        <ul>
        <li><a href="#hash_append_rules">Rules Relating <code>hash_append</code> to <code>operator==</code></a></li>
        </ul>
    </li>
    <li><a href="#hash_append_vector"><code>hash_append</code> for <code>vector&lt;T, A&gt;</code></a></li>
    <li><a href="#hash_append_pair"><code>hash_append</code> for <code>std::pair&lt;T, U&gt;</code></a></li>
    <li><a href="#hash_append_int"><code>hash_append</code> for <code>int</code></a></li>
    <li><a href="#is_contiguously_hashable">An Optimization: <code>is_contiguously_hashable&lt;T&gt;</code>:</a></li>
    <li><a href="#strings">Strings are really important.  What say ye about strings?</a></li>
    <li><a href="#hash_combine">Wait a minute.  Isn't <code>hash_append</code> the same thing as <code>boost::hash_combine</code>?</a></li>
    <li><a href="#serialization">Wait a minute.  Isn't <code>hash_append</code> the same thing as serialization?</a></li>
    <li><a href="#variadic">Is there a variadic version of <code>hash_append</code>?</a></li>
    <li><a href="#adapt_algorithm">How easily can algorithms other than FNV-1a be used?</a></li>
    <li><a href="#switch_algorithm">What is involved in switching hashing algorithms?</a></li>
    <li><a href="#pimpl">How does one <code>hash_append</code> Pimpl designs?</a></li>
    <li><a href="#seeding">How does one apply random seeding?</a></li>
    <li><a href="#testing">How does the quality of the resulting hash codes compare to the <code>hash_combine</code> solution?</a></li>
    </ul>
</li>
<li><a href="#Summary">Summary</a>
    <ul>
    <li><a href="#proposedinfrastructure">Summary of proposed infrastructure</a></li>
    </ul>
</li>
<li><a href="#debugHasher">Appendix A: <code>debugHasher</code></a></li>
<li><a href="#Acknowledgments">Acknowledgments</a></li>
</ul>

<a name="Introduction"></a><h2>Introduction</h2>

<p>
This paper proposes a new hashing infrastructure that completely decouples
hashing algorithms from individual types that need to be hashed.  This
decoupling divides the hashing computation among 3 different programmers who
need not coordinate with each other:
</p>

<ol>
<li><p>
Authors of types to be hashed (keys of type <code>K</code>) write their hashing
support just once, using no specific hashing algorithm.  This code resembles
(and is approximately the same amount of work as) <code>operator==</code> and
<code>swap</code> for a type.
</p></li>
<li><p>
Authors of hashing algorithms write a functor (e.g. <code>H</code>) that
operates on a contiguous chunk of generic memory, represented by a <code>void
const*</code> and a number of bytes.  This code has no concept of a specific key
type, only of bytes to be hashed.
</p></li>
<li><p>
Clients who want to hash keys of type <code>K</code> using hashing algorithm
<code>H</code> will form a functor of type <code>std::uhash&lt;H&gt;</code> to
give to an unordered container.
</p>
<blockquote><pre>
unordered_set&lt;K, uhash&lt;H&gt;&gt; my_set;
</pre></blockquote>
<p>
Naturally, there could be a default hashing algorithm supplied by the std::lib:
</p>
<blockquote><pre>
unordered_set&lt;K, uhash&lt;&gt;&gt; my_set;
</pre></blockquote>
</li>
</ol>

<p>
To start off with, we emphasize:  there is nothing in this proposal that changes
the existing <code>std::hash</code>, or the unordered containers.  And there is
also nothing in this proposal that would prohibit the committee from standardizing
both this proposal, and either one of
<a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2012/n3333.html">N3333</a>
or
<a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n3876.pdf">N3876</a>.
<a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2012/n3333.html">N3333</a>
and
<a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n3876.pdf">N3876</a>
contradict each other, and thus compete with each other.  Both can not be
standardized.  This proposal, on the other hand, addresses a problem not addressed
by 
<a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2012/n3333.html">N3333</a>
or
<a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n3876.pdf">N3876</a>.
Nor does this proposal depend upon anything in 
<a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2012/n3333.html">N3333</a>
or
<a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n3876.pdf">N3876</a>.
</p>

<p>
This paper simply takes a completely different approach to producing hash
codes from types, in order to solve a problem that was beyond the scope of
<a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2012/n3333.html">N3333</a>
and
<a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n3876.pdf">N3876</a>.
The problem solved herein is how to support the hashing of N different types of
keys using M different hashing algorithms, using an amount of source code that
is proportional to N+M, as opposed to the current system based on
<code>std::hash&lt;T&gt;</code> which requires an amount of source code
proportional to N*M.  And consequently in practice today M==1, and the single
hashing algorithm is supplied only by the std::lib implementor. As it is too
difficult and error prone for the client to supply alternative algorithms for
all of the built-in scalar types (<code>int</code>, <code>long</code>,
<code>double</code>, etc.).  Indeed, it has even been too difficult for the
committee to supply hashing support for all of the types our clients might
reasonably want to use as keys: <code>pair</code>, <code>tuple</code>,
<code>vector</code>, <code>complex</code>, <code>duration</code>,
<code>forward_list</code> etc.
</p>

<p>
This paper makes ubiquitous hash support for types as easy and as practical as
is today's support for <code>swap</code> and <code>operator==</code>.
</p>

<p>
This paper starts with an assertion:
</p>

<blockquote class=note><p>
Types should not know how to hash themselves.
</p></blockquote>

<p>
The rest of this paper begins with demonstrating the problems created when
software systems assume that types do know how to hash themselves, and what
can be done to solve these problems.
</p>

<a name="Example"></a><h2>The Example</h2>

<p>
Instead of starting with a basic example like <code>std::string</code> or
<code>int</code>, this paper will introduce an example class X
that is meant to be representative of a type that a programmer would write,
and would want to create a hash code for:
</p>

<blockquote><pre>
class X
{
    std::tuple&lt;short, unsigned char, unsigned char&gt; date_;
    std::vector&lt;std::pair&lt;int, int&gt;&gt;                data_;

public:
    X();
    // ...
    friend bool operator==(X const&amp; x, X const&amp; y)
    {
        return std::tie(x.date_, x.data_) == std::tie(y.date_, y.data_);
    }
};
</pre></blockquote>

<blockquote class=note><p>
How do we write the hash function for X?
</p></blockquote>

<a name="Solution1"></a><h2>Solution 1: Specialize <code>std::hash&lt;X&gt;</code></h2>

<p>
If we standardize
<a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n3876.pdf">N3876</a>
which gives us <code>hash_combine</code> and <code>hash_val</code> from
<a href="http://www.boost.org/doc/libs/1_55_0/doc/html/hash/combine.html">boost</a>,
then this is relatively doable:
</p>

<blockquote><pre>
namespace std
{

template &lt;&gt;
struct hash&lt;X&gt;
{
    size_t
    operator()(X const&amp; x) const noexcept
    {
        size_t h =      hash&lt;tuple_element&lt;0, decltype(x.date_)&gt;::type&gt;{}(get&lt;0&gt;(x.date_));
        hash_combine(h, hash&lt;tuple_element&lt;1, decltype(x.date_)&gt;::type&gt;{}(get&lt;1&gt;(x.date_)));
        hash_combine(h, hash&lt;tuple_element&lt;2, decltype(x.date_)&gt;::type&gt;{}(get&lt;2&gt;(x.date_)));
        for (auto const&amp; p : x.data_)
        {
            hash_combine(h, hash&lt;decltype(x.data_)::value_type::first_type&gt;{} (p.first));
            hash_combine(h, hash&lt;decltype(x.data_)::value_type::second_type&gt;{} (p.second));
        }
        return h;
    }
};

}  // std
</pre></blockquote>

<p>
And we also need to add a <code>friend</code> statement to our class X:
</p>

<blockquote><pre>
friend class std::hash&lt;X&gt;;
</pre></blockquote>

<a name="Solution1B"><h3>What about implementing it with
<a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2012/n3333.html">N3333</a>?</h3>

<p>
We were surprised when we attempted to implement <code>std::hash&lt;X&gt;</code>
using the tools proposed in
<a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2012/n3333.html">N3333</a>
and were thwarted.  We had thought that the <code>hash_combine</code> proposed
here (which is different than that in
<a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n3876.pdf">N3876</a>)
would be more helpful.  And we thought we could use the proposed
<code>hash_combine_range</code> as well.  This is as far as we got:
</p>

<blockquote><pre>
template &lt;&gt;
struct hash&lt;X&gt;
{
    std::size_t
    operator()(X const&amp; x) noexcept
    {
        std::size_t h = hash_combine(std::get&lt;0&gt;(x.date_), std::get&lt;1&gt;(x.date_),
                                     std::get&lt;2&gt;(x.date_));
        std::size_t h2 = hash_combine_range(x.data_.begin(), x.data_.end());
        return my_own_hash_combine(h, h2);
    }
};
</pre></blockquote>

<p>
The problem came when we tried to combine two <i>already computed</i> hash codes.
For review, here is a summary:
</p>

<ul>
<li>
<p>
The <a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2012/n3333.html">N3333</a>
<code>hash_combine</code> will hash two objects, combine their hash codes, and
return one hash code.
</p>
</li>
<li>
<p>
The <a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n3876.pdf">N3876</a>
<code>hash_combine</code> (and the <code>boost::hash_combine</code>) will take
one hash code and one object, hash the object, and combine the new hash code
into the old one.
</p>
</li>
<li>
<p>
We found what we needed was something that takes two hash codes, and combines
them into one hash code.  So we had to roll our own (<code>my_own_hash_combine</code>).
</p>
</li>
</ul>

<a name="Solution1C"><h3>What about implementing it only with C++14 tools?</h3>

<p>
Our C++14-only implementation of <code>std::hash&lt;X&gt;</code> ended up looking
just like the 
<a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n3876.pdf">N3876</a>
version, except using a hand-rolled <code>hash_combine</code>.
</p>

<p>
Now we can say <code>std::hash&lt;X&gt;{}(x)</code> and we get back a
hash code.  Is it a <i>good</i> hash code? <i>&lt;shrug&gt;</i>.  The
quality of the hash code is unknown.  What hashing algorithm has been
used? <i>&lt;shrug&gt;</i>.  The hashing algorithm is unspecified.  Later
in this paper we will attempt to at least partially answer these questions.
</p>

<p>
Ok, what if we can't leave things up to chance?  We want to use a
hashing algorithm that is known to have some given verifiable
qualities.  How do we do that?
</p>

<a name="Solution2"><h2>Solution 2: Make use of a well-known hashing algorithm</h2>

<p>
There are many hash algorithms freely available, and several of them explored
in <a href="http://blog.aggregateknowledge.com/2011/12/29/choosing-a-good-hash-function-part-2/">this blog</a>.
Which of these algorithms should we use?  Assuming we pick one, how do we
use that algorithm?  As a simple example, let's assume that we wish to use
<a href="http://www.isthe.com/chongo/tech/comp/fnv/index.html">FNV-1a</a>
which can be coded up like this:
</p>

<blockquote><pre>
std::size_t
do_fnv1a (void const* key, std::size_t len)
{
    unsigned char const* p = static_cast&lt;unsigned char const*&gt;(key);
    unsigned char const* const e = p + len;
    std::size_t h = 14695981039346656037u;
    for (; p &lt; e; ++p)
        h = (h ^ *p) * 1099511628211u;
    return h;
}
</pre></blockquote>

<p>
We have picked FNV-1a, not because it is the best hash algorithm.  There are
more modern ones which we will also explore.  We've picked FNV-1a because it
combines reasonable quality with excellent simplicity, making it ideal to
demonstrate the main concept of this paper.
</p>

<p>
One point should be made very clear, right up front:
</p>

<blockquote class=note>
<p>
Neither
<a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2012/n3333.html">N3333</a>
nor
<a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n3876.pdf">N3876</a>
offer any aid whatsoever to the programmer who wants to specify or adopt an
existing open-source hashing algorithm.  These two papers only further package
what C++11 already offers:  A single, unspecified, std::lib-supplied hashing
algorithm.
</p>
<p>
<a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2012/n3333.html">N3333</a>
acknowledges this fact in
<a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2012/n3333.html#future">Future work</a>.
</p>
<p>
This proposal <i>is</i> that future work.  Just by different authors.
</p>
</blockquote>

<p>
In the description that follows, this is how we would implement a custom hash
functor which uses the FNV-1a algorithm.  This implementation is a reasonable
implementation technique, <b>whether or not</b>
<a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2012/n3333.html">N3333</a>
or <a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n3876.pdf">N3876</a>
is standardized.  Since neither of those proposals aid in adapting existing
hashing algorithms, the tools from neither are used below.
</p>

<p>
On our system, both <code>std::pair&lt;int, int&gt;&gt;</code> and 
<code>std::tuple&lt;short, unsigned char, unsigned char&gt;</code> are what we
refer to as <i>contiguously hashable</i>.  More on that concept below, but
consider it to be used for the same purpose that
<a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2012/n3333.html">N3333</a>
uses <code>is_contiguous_layout&lt;T&gt;</code>.
</p>

<p>
It is now convenient to write a custom hash functor that works for any type
<code>T</code> which is <i>contiguously hashable</i>:
</p>

<blockquote><pre>
template &lt;class T&gt;
struct fnv1a_hash
{
    static_assert(is_contiguously_hashable&lt;T&gt;::value, "");

    std::size_t
    operator() (T const&amp; t) const
    {
        return do_fnv1a(std::addressof(t), sizeof(t));
    }

    std::size_t
    operator() (T const*  t, std::size_t len) const
    {
        return do_fnv1a(t, sizeof(T)*len);
    }
};
</pre></blockquote>

<p>
This convenience functor wraps the existing FNV-1A algorithm up so that it can
be used two ways:
</p>

<ol>
<li>To hash a single <code>T</code>.</li>
<li>To hash a contiguous range of <code>T</code>.</li>
</ol>

<p>
In both cases, it is wise to <code>static_assert</code> that <code>T</code>
actually <i>is contiguously hashable</i>.  As a start, this trait can answer
true for two's complement integral types, and for types such as <code>pair</code>
and <code>tuple</code> when these containers consist only of types which answer
true to <code>is_contiguously_hashable</code>, and when the sum of the
<code>sizeof</code> of each data member is the same as the <code>sizeof</code>
the entire <code>pair</code> or <code>tuple</code> (and thus there are no
padding bytes).
</p>

<p>
Now we can specialize <code>fnv1a_hash</code> for X, which is not contiguously
hashable:
</p>

<blockquote><pre>
template &lt;&gt;
struct fnv1a_hash&lt;X&gt;
{
    std::size_t
    hash_combine(std::size_t x, std::size_t y)
    {
        return x ^ (y + 0x9e3779b9 + (x&lt;&lt;6) + (x&gt;&gt;2));
    }

    std::size_t
    operator()(X const&amp; x) noexcept
    {
        std::size_t h = fnv1a_hash&lt;decltype(x.date_)&gt;{} (x.date_);
        h = hash_combine(h, fnv1a_hash&lt;decltype(x.data_)::value_type&gt;{}
                                              (x.data_.data(), x.data_.size()));
        h = hash_combine(h, fnv1a_hash&lt;std::size_t&gt;{} (x.data_.size()));
        return h;
    }
};
</pre></blockquote>

<p>
Now we can use this new functor in <code>unordered_set</code>:
</p>

<blockquote><pre>
std::unordered_set&lt;X, fnv1a_hash&lt;X&gt;&gt; my_set;
</pre></blockquote>

<p>
Naturally if we add <code>OtherType</code> as a member to X (and if that
new type participates in the equality computation for X), then we need to
add a call to <code>fnv1a_hash&lt;OtherType&gt;</code> to X's computation,
and then we need to implement <code>fnv1a_hash&lt;OtherType&gt;</code>, and
we need to implement <code>fnv1a_hash</code> specializations for any
non-contiguously hashable types which <code>OtherType</code> uses.
</p>

<blockquote class=note>
This design in general requires O(N) implementation work per hash algorithm
where N is the number of unique non-contiguously hashable sub-types of the type
to be hashed, plus the number of sub-types, of the sub-types, etc.
</blockquote>

<p>
If we now want to implement 
<a href="http://burtleburtle.net/bob/hash/spooky.html">SpookyHash</a>
or
<a href="https://code.google.com/p/cityhash/">CityHash</a>
or
<a href="https://code.google.com/p/smhasher/wiki/MurmurHash3">MurmurHash3</a>
or
<a href="https://131002.net/siphash/">SipHash</a>,
then we need to reimplement hash functor specializations for each of
these algorithms <i>times</i> each non-contiguously hashable sub-type of
interest.  All of this code will have very similar structure.  It will just
be a lot of error-prone copy/pasting.
</p>

<p>
Imagine that you have just implemented 5 hashing algorithms for X and X's
subtypes.  Now you can easily switch between the hashing algorithms for
performance and quality testing.  For arguments sake, let's assume that X has 4
unique non-contiguously hashable subtypes.  So you've implemented 25 hashing
algorithms, on top of the 5 algorithms that implement each hash algorithm on
contiguously hashable types.
</p>

<p>
Now there is a change to X:  The first two data members have slight changes:
</p>

<blockquote><pre>
class X
{
    std::tuple&lt;<del>short</del><ins>int</ins>, unsigned char, unsigned char&gt; date_;
    std::vector&lt;std::pair&lt;int, <del>int</del><ins>char</ins>&gt;&gt; data_;
    // ...
</pre></blockquote>

<p>
You recompile, and the resulting avalanche of compile-time errors overwhelms
you!  It could have been worse ... had we not included
</p>

<blockquote><pre>
static_assert(is_contiguously_hashable&lt;T&gt;::value, "");
</pre></blockquote>

<p>
then everything would have compiled fine, and we would have been stuck with
many extremely difficult-to-debug run-time errors.
</p>

<p>
How do we fix these errors?
</p>

<p>
The first thing to look at is the <code>fnv1a_hash&lt;X&gt;</code>
specialization.  Our previous implementation assume <code>date_</code> and
the <code>value_type</code> of <code>data_</code> were contiguously hashable.
That assumption is now false.  Here is how <code>fnv1a_hash&lt;X&gt;</code>
must be coded now:
</p>

<blockquote><pre>
struct fnv1a_hash&lt;X&gt;
{
    std::size_t
    hash_combine(std::size_t x, std::size_t y)
    {
        return x ^ (y + 0x9e3779b9 + (x&lt;&lt;6) + (x&gt;&gt;2));
    }

    std::size_t
    operator()(X const&amp; x) noexcept
    {
        std::size_t h = fnv1a_hash&lt;std::tuple_element&lt;0, decltype(x.date_)&gt;::type&gt;{}
                                                              (std::get&lt;0&gt;(x.date_));
        h = hash_combine(h, fnv1a_hash&lt;std::tuple_element&lt;1, decltype(x.date_)&gt;::type&gt;{}
                                                              (std::get&lt;1&gt;(x.date_)));
        h = hash_combine(h, fnv1a_hash&lt;std::tuple_element&lt;2, decltype(x.date_)&gt;::type&gt;{}
                                                              (std::get&lt;2&gt;(x.date_)));
        for (auto const&amp; p : x.data_)
        {
            h = hash_combine(h, fnv1a_hash&lt;decltype(x.data_)::value_type::first_type&gt;{}
                                                                         (p.first));
            h = hash_combine(h, fnv1a_hash&lt;decltype(x.data_)::value_type::second_type&gt;{}
                                                                         (p.second));
        }
        h = hash_combine(h, fnv1a_hash&lt;std::size_t&gt;{}(x.data_.size()));
        // combine in contribution from other types...
        return h;
    }
};
</pre></blockquote>

<p>
This also may need to be done for the 4 other hypothetical sub-types of X.
It also needs to be repeated for each of the other 4 hashing algorithms (i.e.
24 other places).
</p>

<p>
This approach does not scale!
</p>

<p>
We have a N hashing algorithms x M sub-types problem.  And just like the
N general algorithms x M containers problem was solved by the elegant design
of the STL, this problem can also be solved.
</p>

<p>
This proposal solves the N hashing algorithms x M sub-types problem.
Neither
<a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2012/n3333.html">N3333</a>
nor
<a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n3876.pdf">N3876</a>
contribute anything at all to the solution to this problem.  This problem was
beyond their scope.
</p>

<p>
The key to solving this problem is the recognition of one simple observation:
</p>

<blockquote class=note><p>
Types should not know how to hash themselves.  However types do know what parts
of their state should be exposed to a hashing algorithm.
</p></blockquote>

<p>
The question now becomes:  How do you present X to a general purpose hashing
algorithm without binding it to any specific algorithm?
</p>

<a name="generalpurpose"></a><h2>How to get X to use a general purpose hashing algorithm</h2>

<p>
Although most modern hashing algorithms are much more complicated than
<code>fnv1a</code> shown above, there are similarities among them.
</p>

<ul>
<li>They generally take a stream of bytes as their input.  This is often
specified as a  <code>void const*</code> and a <code>size_t</code> length.</li>

<li>
This interface implies that they work on a contiguous array of bytes.
</li>

<li>
The algorithms generally have an initialization stage, often taking an
optional seed, followed by an accumulation stage which depends on the
supplied bytes, followed by a finalization stage after all of the bytes
are consumed.
</li>
</ul>

<p>
Not all, but many of the algorithms also have the property that they consume
bytes in the order that they are received, possibly with a fixed sized internal
buffer.  In the FNV-1a example, that internal buffer is reduced down to a
single byte.  This characteristic can be taken advantage of in order to hash
<i>discontiguous</i> memory.
</p>

<p>
For example consider this minor repackaging of the FNV-1a algorithm:
</p>

<blockquote><pre>
class fnv1a
{
    std::size_t state_ = 14695981039346656037u;
public:
    using result_type = std::size_t;

    void
    operator()(void const* key, std::size_t len) noexcept
    {
        unsigned char const* p = static_cast&lt;unsigned char const*&gt;(key);
        unsigned char const* const e = p + len;
        for (; p &lt; e; ++p)
            state_ = (state_ ^ *p) * 1099511628211u;
    }

    explicit
    operator result_type() noexcept
    {
        return state_;
    }
};
</pre></blockquote>

<p>
Now the algorithm can be accessed in 3 stages:
</p>

<ol>
<li>The algorithm is initialized in a constructor, in this case the
implicit default constructor.  Other constructors / initializations
should be possible.  But we start out with this simplest of algorithms.</li>
<li>The algorithm consumes bytes in the <code>operator()(void const* key,
std::size_t len)</code> function. Note that this function can be called any
number of times.  In each call the memory is contiguous.  But there is no
requirement at all that separate calls refer to a single block of memory.</li>
<li>The algorithm is finalized when the object is converted to a
<code>result_type</code> (in this case a <code>size_t</code>).
This is the finalization stage, which in this
case is trivial, but could be arbitrarily complex.</li>
</ol>

<p>
We can say that <code>fnv1a</code> meets the requirements of a
<code>Hasher</code>.  A <code>Hasher</code> is a class type that can be
constructed (default, or possibly with seeding), has an <code>operator()</code>
member function with the signature represented above.  The
<code>operator()</code> member function processes bytes, updating the internal
state of the <code>Hasher</code>.  This internal state can be arbitrarily
complex.  Indeed an extreme example of internal state could be a copy of every
chunk of memory supplied to the <code>Hasher</code>.  And finally a
<code>Hasher</code> can be explicitly converted to the nested type
<code>result_type</code>, which when used with the unordered containers should
be an alias for <code>size_t</code>.
</p>

<a name="Universal"></a><h3>Introducing the Universal hash function!</h3>

<p>
Given the concept of <code>Hasher</code>, a universal hash functor, which
takes <b>any</b> type <code>T</code> can now be written (almost):
</p>

<blockquote><pre>
template &lt;class Hasher&gt;
struct uhash
{
    using result_type = typename Hasher::result_type;

    template &lt;class T&gt;
    result_type
    operator()(T const&amp; t) const noexcept
    {
        Hasher h;
        using std::hash_append;
        hash_append(h, t);
        return static_cast&lt;result_type&gt;(h);
    }
};
</pre></blockquote>

<p>
Now one can use <code>uhash&lt;fnv1a&gt;</code> as the hash function for
<code>std::unordered_map</code>, for example:
</p>

<blockquote><pre>
std::unordered_map&lt;MyKey, std::string, uhash&lt;fnv1a&gt;&gt; the_map;
</pre></blockquote>

<p>
First note several important attributes of <code>uhash</code>:
</p>

<ol>
<li>
<code>uhash</code> depends only on the hashing algorithm, which is encapsulated
in the <code>Hasher</code>.  <code>uhash</code> does not depend upon the
type <code>T</code> being hashed.
</li>
<li>
<code>uhash</code> is simple.  Though such a utility should certainly be 
supplied by the std::lib, any programmer can very easily implement their own
variant of <code>uhash</code> for desired customizations (e.g. 
<a href="http://en.wikipedia.org/wiki/Random_seed">random seeding</a>,
<a href="http://en.wikipedia.org/wiki/Salt_(cryptography)">salting</a>,
or <a href="http://en.wikipedia.org/wiki/Padding_(cryptography)">padding</a>),
<b>without</b> having to revisit the hashing code for distinct types.
</li>
<li>
For applications other than unordered containers, and for hashing algorithms
that support it, the programmer can easily create a hash functor that returns
something besides a <code>size_t</code>.  For example, this could come in handy
in computing a <a href="http://en.wikipedia.org/wiki/SHA-2">SHA-256</a>
result.  And all without having to revisit each individual type!
</li>
</ol>

<p>
Let's walk through <code>uhash</code> one step at a time.
</p>

<ol>
<li><p>
The <code>Hasher</code> is constructed (default constructed in this example, but
that is not the only possibility).  This step initializes the hashing algorithm
encapsulated in the <code>Hasher</code>.
</p></li>
<li><p>
It is appended to using <code>t</code> as a key.  The function
<code>hash_append</code> is implemented for each type that supports hashing.
We will see below that such support code need be written only once per type in
order to support many hashing algorithms.  It is implemented in the type's own
namespace, but there are implementations in namespace std for most scalars
(just like <code>swap</code>).
</p></li>
<li><p>
And then the <code>Hasher</code> is explicitly converted to the desired result.
This is where the algorithm is "finalized."
</p></li>
</ol>

<p>
The above <code>hash</code> functor is accessing the generic hashing algorithm
by its 3 distinct phases. Additionally, this <code>hash</code> functor could
even be defaulted to use your favorite hash algorithm:
</p>

<blockquote><pre>
template &lt;class Hasher = fnv1a&gt; struct uhash;
</pre></blockquote>

<p>
The question usually arises now:  Are you proposing that <code>uhash&lt;&gt;</code>
replace <code>hash&lt;T&gt;</code> as the default hash functor in the
unordered containers?  The answer is it really almost doesn't matter.  With
templated using declarations, it is just so easy for programmers to specify
their own defaults:
</p>

<blockquote><pre>
namespace my
{
template &lt;class Key, class T, class Hash = std::uhash&lt;&gt;, class Pred = std::equal_to&lt;Key&gt;,
          class Alloc = std::allocator&lt;std::pair&lt;Key const, T&gt;&gt;&gt;
    using unordered_map = std::unordered_map&lt;Key, T, Hash, Pred, Alloc&gt;;
}  // my

// ...

my::unordered_map&lt;MyKey, std::string&gt; the_map;  // uses std::uhash&lt;&gt; instead of std::hash&lt;MyKey&gt;
</pre></blockquote>


<a name="hash_append"></a><h3>What is <code>hash_append</code>?</h3>

<p>
The <code>hash_append</code> function is the way that individual types
communicate with the <code>Hasher</code>.
</p>

<p>
Each type <code>T</code> is responsible only for exposing its hash-worthy state
to the <code>Hasher</code> in the function  <code>hash_append</code>.
<code>T</code> is <i>not</i> responsible for combining hash codes.  Nor is it
responsible for any hashing arithmetic whatsoever.  It is only responsible for
pointing out where its data is, how many different chunks of data there are,
and what order they should be presented to the <code>Hasher</code>.
</p>

<p>
For example, here is how X might implement <code>hash_append</code>:
</p>

<blockquote><pre>
class X
{
    std::tuple&lt;short, unsigned char, unsigned char&gt; date_;
    std::vector&lt;std::pair&lt;int, int&gt;&gt;                data_;

public:
    // ...
    friend bool operator==(X const&amp; x, X const&amp; y)
    {
        return std::tie(x.date_, x.data_) == std::tie(y.date_, y.data_);
    }

    <b>// Hook into the system like this
    template &lt;class Hasher&gt;
    friend void hash_append(Hasher&amp; h, X const&amp; x) noexcept
    {
        using std::hash_append;
        hash_append(h, x.date_);
        hash_append(h, x.data_);
    }</b>
}
</pre></blockquote>

<p>
Like <code>swap</code>, <code>hash_append</code> is a customization point for
each type.  Only a type knows what parts of itself it should expose to a
<code>Hasher</code>, even though the type has no idea what algorithm is being
used to do the hashing.  Note that X need not concern itself with details like
whether or not its sub-types are <i>contiguously hashable</i>.  Those details
will be handled by the <code>hash_append</code> for the individual sub-types.
The <i>only</i> information the <code>hash_append</code> overload for X must
implement is what sub-types need to be presented to the <code>Hasher</code>,
and in what order.
Furthermore the <code>hash_append</code> function is intimately tied to the
<code>operator==</code> for the same type.  For example if for some reason
<code>x.data_</code> did not participate in the equality computation, then it
should also not participate in the <code>hash_append</code> computation.
</p>

<a name="hash_append_rules"></a><h4>Rules Relating <code>hash_append</code> to <code>operator==</code></h4>

<p>
For all combination of two values of X, <code>x</code> and <code>y</code>, there
are two rules to follow in designing <code>hash_append</code> for type X. 
Actually the second rule is more of a guideline.  But it should be followed as
closely as possible:
</p>

<ol>
<li><p>
If <code>x == y</code>, then both <code>x</code> and <code>y</code> <i>shall</i>
send the same message to the <code>Hasher</code> in <code>hash_append</code>.
</p></li>
<li><p>
If <code>x != y</code>, then <code>x</code> and <code>y</code> <i>should</i>
send different messages to the <code>Hasher</code> in <code>hash_append</code>.
</p></li>
</ol>

<p>
It is very important to keep these two rules in mind when designing the
<code>hash_append</code> function for any type, or for any instantiation of a
class template.  Failure to follow the first rule will mean that equal values
hash to different codes.  Clients such as unordered containers will simply
fail to work, resulting in run time errors if this rule is violated.  Failure
to follow the second guideline will result in hash collisions for the two
different values that send identical messages to the <code>Hasher</code>, and
will thus degrade the performance of clients such as unordered containers.
</p>

<a name="hash_append_vector"></a><h3><code>hash_append</code> for <code>vector&lt;T, A&gt;</code></h3>

<p>
For example <code>std::vector&lt;T, A&gt;</code> would
never expose its <code>capacity()</code>, since <code>capacity()</code> can be
different for <code>vector</code>'s that otherwise compare equal.  Likewise
it should not expose its <code>allocator_type</code> to <code>hash_append</code>,
since this value also does not participate in the equality computation.
</p>

<p>
Should <code>vector</code> expose its <code>size()</code> to the
<code>Hasher</code>? To find out, lets look closer at the
<code>operator==</code> for <code>vector</code>:
</p>

<blockquote><p>
Two <code>vector</code>'s <code>x</code> and <code>y</code> compare equal if
<code>x.size() == y.size()</code> and if <code>x[i] == y[i]</code> for
<code>i</code> in the range of 0 to <code>x.size()</code>.
</p></blockquote>

<p>
To meet <a href="#hash_append_rules">rule 1</a>, it is sufficient that every element in the <code>vector</code>
be sent to the <code>Hasher</code> as part of the <code>vector</code>'s message.
A logical convention is that the elements will be sent in order from
<code>begin()</code> to <code>end()</code>.  But this alone will not satisfy
<a href="#hash_append_rules">rule 2</a>.  Consider:
</p>

<blockquote><pre>
std::vector&lt;std::vector&lt;int&gt;&gt; v1{};
std::vector&lt;std::vector&lt;int&gt;&gt; v2{1};
assert(v1 != v2);
</pre></blockquote>

<p>
<code>v1</code> and <code>v2</code> are not equal.  <code>v1.size() == 0</code>
and  <code>v2.size() == 1</code>.  However <code>v2.front().size() == 0</code>.
If an empty <code>vector&lt;int&gt;</code> sends no message at all to the
<code>Hasher</code>, then <code>v2</code>, even though it is not empty, also
sends no message to the <code>Hasher</code>.  And therefore <code>v1</code> and
<code>v2</code> send the same (0 length) message to the <code>Hasher</code>,
violating <a href="#hash_append_rules">rule 2</a>.
</p>

<p>
One idea for fixing this is to special case 0-length <code>vector</code>s to 
output a special value such as "empty" or 0.  However in the first case the
result would be ambiguous with a <code>vector&lt;string&gt;</code> of length
1 containing the string "empty".  The second case has the exact same problem
but for <code>vector&lt;int&gt;</code>.
</p>

<p>
The right way to fix this problem is to have  <code>vector&lt;T&gt;</code> send
its <code>size()</code> in addition to sending all of its members to the
<code>Hasher</code>.  Now the only question is:  Should it send its
<code>size</code> before or after sending its members to the <code>Hasher</code>?
</p>

<p>
To answer this last question, consider another sequence container:
<code>forward_list&lt;T&gt;</code>.  It has the exact same issues as we have
been discussing for <code>vector&lt;T&gt;</code>, but <code>forward_list&lt;T&gt;</code>
has no <code>size()</code> member.  In order to send its <code>size()</code>,
<code>forward_list&lt;T&gt;</code> has to loop through all of its members to
first compute <code>size()</code>.  In order to avoid the requirement that
<code>hash_append</code> for <code>forward_list&lt;T&gt;</code> make two
passes through the list, we should specify that the <code>size()</code> of the
container is sent to the <code>Hasher</code> <i>after</i> all of the elements
are sent.  And for consistency, we should do this for all std-containers for
which <code>hash_append</code> is defined.
</p>

<blockquote><pre>
template &lt;class Hasher, class T, class Alloc&gt;
void
hash_append(Hasher&amp; h, std::vector&lt;T, Alloc&gt; const&amp; v) noexcept
{
    for (auto const&amp; t : v)
        hash_append(h, t);
    hash_append(h, v.size());
}
</pre></blockquote>

<p>
I.e. <code>vector</code> considers itself a message composed of 0 or more
sub-messages, and appends each sub-message (in order) to the state of the
generic <code>Hasher</code>.  And this is followed with a final message
consisting of the <code>size()</code> of the <code>vector</code>.
</p>

<p>
Note that as
<a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2012/n3333.html">N3333</a>
and
<a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n3876.pdf">N3876</a>
both stand today, this critically important but subtle detail is not treated,
and is left up to the client (the author of X) to get right.  This proposal
states that this is a detail that the <code>hash_append</code> for
<code>vector</code> (and every other hashable std-container) is responsible for.
</p>

<p><b>Emphasis</b></p>
<blockquote><p>
The message a type sends to a <code>Hasher</code> is part of its public API.
E.g. whether or not a container includes its <code>size()</code> in its
<code>hash_append</code> message, and if so, whether the  <code>size()</code> is
prepended or appended to the message, is critical information a type's client
needs to know, in order to ensure that their composition of some type's message
with another type's message doesn't produce an ambiguous message (doesn't create
collisions).
</p><p>
The standard should clearly document the message emanating from every
<code>hash_append</code> it defines, to the extent possible. It might not be
possible to nail down that an implementation is using IEEE floating point or
two's complement signed integers.  But the standard can certainly document
the message produced by a <code>vector</code> or any other std-defined class
type.
</p></blockquote>

<a name="hash_append_pair"></a><h3><code>hash_append</code> for <code>std::pair&lt;T, U&gt;</code></h3>

<p>
The situation is simpler for <code>std::pair&lt;T, U&gt;</code>:
</p>

<blockquote><pre>
template &lt;class Hasher, class T, class U&gt;
void
hash_append (Hasher&amp; h, std::pair&lt;T, U&gt; const&amp; p) noexcept
{
    hash_append (h, p.first);
    hash_append (h, p.second);
}
</pre></blockquote>

<p>
All there is to do is to just <code>hash_append</code> the first and second
members of the pair.
</p>

<a name="hash_append_int"></a><h3><code>hash_append</code> for <code>int</code></h3>

<p>
Eventually <code>hash_append</code> will drill down to a scalar type such as
<code>int</code>:
</p>

<blockquote><pre>
template &lt;class Hasher&gt;
void
hash_append(Hasher&amp; h, int const&amp; i) noexcept
{
    h(&amp;i, sizeof(i));
}
</pre></blockquote>

<p>
Whereupon a contiguous chunk of memory is actually accumulated by the
<code>Hasher</code>, using the <code>Hasher</code>'s <code>operator()</code>.
 Recall that the <code>Hasher</code> has a member function
<code>operator()(const void* key, std::size_t len) noexcept</code>.  And the
<code>int</code> is just a chunk of <i>contiguous</i> memory that is
<i>hashable</i>.  It is now prudent to deeply consider what it means to say
that a type (such as <code>int</code>) is <i>contiguously hashable</i>.
</p>

<p>
A type <code>T</code> is <i>contiguously hashable</i> if for all combinations of
two values of a type, say <code>x</code> and <code>y</code>, if <code>x ==
y</code>, then it must also be true that <code>memcmp(addressof(x),
addressof(y), sizeof(T)) == 0</code>.  I.e. if <code>x == y</code>, then
<code>x</code> and <code>y</code> have the same bit pattern representation. A
2's complement <code>int</code> satisfies this property because every bit
pattern an <code>int</code> can have results in a distinct value (<a
href="#hash_append_rules">rule 2</a>).  And there are no "padding bits" which might take on
random values.  This property is necessary because if two values are equal, then
they must hash to the same hash code (<a href="#hash_append_rules">rule 1</a>).
</p>

<a name="is_contiguously_hashable"></a><h3>An Optimization: <code>is_contiguously_hashable&lt;T&gt;</code>:</h3>

<p>
With that in mind we can easily imagine a type trait:
</p>

<blockquote><pre>
template &lt;class T&gt; struct is_contiguously_hashable;
</pre></blockquote>

<p>
which derives from either <code>true_type</code> or <code>false_type</code>. And
on 2's complement systems,
<code>is_contiguously_hashable&lt;int&gt;::value</code> is <code>true</code>.
And we might anticipate that some other types, such as <code>char</code> and
<code>long long</code> are also <i>contiguously hashable</i>.  With this
tool we can now easily write <code>hash_append</code> for all contiguously
hashable types:
</p>

<blockquote><pre>
template &lt;class Hasher, class T&gt;
inline
std::enable_if_t
&lt;
    is_contiguously_hashable&lt;T&gt;::value
&gt;
hash_append(Hasher&amp; h, T const&amp; t) noexcept
{
    h(addressof(t), sizeof(t));
}
</pre></blockquote>

<p>
Now the task remains to specialize <code>is_contiguously_hashable</code>
properly for those scalars we want to use this implementation of
<code>hash_append</code> for, and for any other scalars, implement
<code>hash_append</code> appropriately.  As an example of the latter, consider
IEEE floating point types.
</p>

<p>
An IEEE floating point type is <i>not contiguously hashable</i> because <code>0.
== -0.</code> but these two values are represented with different bit patterns. 
<a href="#hash_append_rules">Rule 1</a> would be violated if hashed contiguously. Therefore the
<code>hash_append</code> for IEEE floating point types must go to extra effort
to ensure that <code>0.</code> and <code>-0.</code> hash to identical hash
codes, but <b>without</b> dictating a specific hash algorithm.  This could be
done like so:
</p>

<blockquote><pre>
template &lt;class Hasher, class T&gt;
inline
std::enable_if_t
&lt;
    std::is_floating_point&lt;T&gt;::value
&gt;
hash_append(Hasher&amp; h, T t) noexcept
{
    if (t == 0)
        t = 0;
    h(&amp;t, sizeof(t));
}
</pre></blockquote>

<p>
I.e. if the value is -0., reset the value to 0., and <i>then</i> contiguously
hash the resulting bits.
</p>

<p>
<a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2012/n3333.html">N3333</a>
also introduced a very similar <code>is_contiguous_layout</code> trait.  We
build upon but modify their idea here.  Just because a type has a
<i>contiguous layout</i> does not necessarily imply that a type is
<i>contiguously hashable</i>.  IEEE floating point is a case in point.  IEEE
floating point does have a contiguous layout (and is trivially copyable, and
has a standard layout).  And yet still it is not <i>contiguously hashable</i>
because of how its <code>operator==</code> works with signed zeros (violating
<a href="#hash_append_rules">rule 1</a>).
</p>

<p>
Class types that are composed of only  <i>contiguously hashable</i> types
and that have no padding bytes, may also be considered to be
<i>contiguously hashable</i>.  For example consider this specialization of
<code>is_contiguously_hashable&lt;std::pair&lt;T, U&gt;&gt;</code>:
</p>

<blockquote><pre>
template &lt;class T, class U&gt;
struct is_contiguously_hashable&lt;std::pair&lt;T, U&gt;&gt;
    : public std::integral_constant&lt;bool, is_contiguously_hashable&lt;T&gt;::value &amp;&amp;
                                          is_contiguously_hashable&lt;U&gt;::value &amp;&amp;
                                          sizeof(T) + sizeof(U) == sizeof(std::pair&lt;T, U&gt;)&gt;
{
};
</pre></blockquote>

<p>
In English:  If the <code>pair</code>'s two types are both contiguously
hashable, and if the size of the two members is the same size as the
<code>pair</code> (so there are no padding bytes), then the entire
<code>pair</code> itself is contiguously hashable!
</p>

<p>
This same logic can be applied to <code>array</code>, <code>tuple</code>, and
possibly user-defined types as well (but only with the user-defined type's
author's permission).  Consequently, a great many types can be easily and safely
classified as contiguously hashable.  This is important because with modern hash
algorithm implementations, the bigger the chunk of contiguous memory you can
send to the <code>Hasher</code> at one time, the higher the performance (in
terms of bytes-hashed/second) the <code>Hasher</code> is likely to perform.
</p>

<p>
With that in mind (the bigger the memory chunk the better), consider again
<code>hash_append</code> for <code>vector</code>:
</p>

<blockquote><pre>
template &lt;class Hasher, class T, class Alloc&gt;
inline
std::enable_if_t
&lt;
    !is_contiguously_hashable&lt;T&gt;::value
&gt;
hash_append(Hasher&amp; h, std::vector&lt;T, Alloc&gt; const&amp; v) noexcept
{
    for (auto const&amp; t : v)
        hash_append(h, t);
    hash_append(h, v.size());
}

template &lt;class Hasher, class T, class Alloc&gt;
inline
std::enable_if_t
&lt;
    is_contiguously_hashable&lt;T&gt;::value
&gt;
hash_append(Hasher&amp; h, std::vector&lt;T, Alloc&gt; const&amp; v) noexcept
{
    h(v.data(), v.size()*sizeof(T));
    hash_append(h, v.size());
}
</pre></blockquote>

<p>
I.e. if the <code>T</code> <b>is</b> contiguously hashable, then even though
<code>vector</code> itself is not, there can still be a <i>huge</i> optimization
made by having <code>vector</code> send its <i>contiguous</i> <code>data</code>
buffer to <code>hash_append</code>.
</p>

<p>
Note that this <b>is</b> a pure optimization.  I.e. the <code>Hasher</code>
sees the <i>exact</i> same sequence of bytes, in the same order, whether or
not this optimization for <code>vector</code> is done.  But if it is done,
then the <code>Hasher</code> sees almost all of the bytes at once.
</p>

<p>
This optimization could be made for <code>vector</code> without any help from the
<code>std::lib</code>. Other optimizations are possible, but could only be made
from within the <code>std::lib</code>.  For example, what if <code>T</code> is
<code>bool</code> in the above example?  <code>vector&lt;bool&gt;</code> doesn't
follow the usual <code>vector</code> rules.  What about
<code>deque&lt;T&gt;</code>?  It could hash its internal contiguous buffers all
at once, but there is no way to implement that without intimate knowledge of the
internals of the <code>deque</code> implementation.  Externally, the best one
can do for <code>deque&lt;T&gt;</code> is to send each individual <code>T</code>
to <code>hash_append</code> one at a time.  This still gives the very same
correct message, but is just much slower.
</p>

<p>
Because only the std::lib implementor can fully implement this optimization for
types such as <code>deque</code>, <code>bitset</code> and
<code>vector&lt;bool&gt;</code>, it is important that we standardize
<code>is_contiguously_hashable</code> and <code>hash_append</code> instead of
asking the programmer to implement them (for std-defined types).
</p>

<p>
If you believe <b>your type</b> to be contiguously hashable, you should
specialize <code>is_contiguously_hashable&lt;YourType&gt;</code> appropriately,
as has been shown for <code>pair</code>.  This would mean that not only is
hashing <code>YourType</code> optimized, but hashing
<code>vector&lt;YourType&gt;</code>, et. al. is also optimized!  But note that
there is no bullet proof way to automate the registration of
<code>YourType</code> with <code>is_contiguously_hashable</code> as IEEE
floating point so ably demonstrates.  To do so requires an in depth analysis
of <code>operator==</code> for <code>YourType</code>, which only the author
of <code>YourType</code> is qualified to do.
</p>

<a name="strings"></a><h3>Strings are really important.  What say ye about strings?</h3>

<p>
Like <code>vector</code>, <code>basic_string</code> can be optimized if the
<code>CharT</code> is contiguously hashable, as it will be for any reasonable
<code>CharT</code>.  But there is an interesting and useful wrinkle...
</p>

<p>
C-style arrays are also hashable:
</p>

<blockquote><pre>
template &lt;class Hasher, class T, std::size_t N&gt;
inline
std::enable_if_t
&lt;
    !is_contiguously_hashable&lt;T&gt;::value
&gt;
hash_append(Hasher&amp; h, T (&amp;a)[N]) noexcept
{
    for (auto const&amp; t : a)
        hash_append(h, t);
}
</pre></blockquote>

<p>
And if <code>T</code> <i>is</i> contiguously hashable, then the generic
<code>hash_append</code> works for C-style arrays (as long as we specialize
<code>is_contiguously_hashable&lt;T[N]&gt;</code>) appropriately.  And, well
this is the good part, the decltype(a-string-literal) is a C-style array type.
For string literals, the array type is always one larger than the
<code>strlen</code> of the literal because the array contains the trailing null
character.  And, by happy coincidence, <code>basic_string</code> now always
embeds a trailing null character as well.  So optimized or not, the
<code>hash_append</code> for <code>basic_string</code> should be specified
to include hashing the trailing null character:
</p>

<blockquote><pre>
template &lt;class Hasher, class CharT, class Traits, class Alloc&gt;
inline
std::enable_if_t
&lt;
    is_contiguously_hashable&lt;CharT&gt;::value
&gt;
hash_append(Hasher&amp; h, std::basic_string&lt;CharT, Traits, Alloc&gt; const&amp; s) noexcept
{
    h(s.data(), (s.size()+1)*sizeof(CharT));
}
</pre></blockquote>

<p>
With this definition, then there is an invariant relationship between
<code>std::string</code> and string literals, no matter what hashing algorithm
is specified by the client:
</p>

<blockquote><pre>
assert(uhash&lt;&gt;{}(std::string("Hi!")) == uhash&lt;&gt;{}("Hi!"));
assert(uhash&lt;MySpecialHasher&gt;{}(std::string("Hi!")) == uhash&lt;MySpecialHasher&gt;{}("Hi!"));
</pre></blockquote>

<p>
String literals and their <code>std::basic_string</code> counterparts hash
identically!  When you think about it in terms of messages, this makes perfect
sense.  Is <code>std::string{"some text"}</code> a different message than
<code>"some text"</code>?  Of course not.  The two identical messages simply
have different storage mechanisms.  They actually compare equal, and thus should
have identical hash codes as well (no matter the hashing algorithm).
This opens the door for the unordered container analogue of:
</p>

<blockquote><pre>
template &lt;class K&gt; iterator find(const K&amp; x);
</pre></blockquote>

<p>
to actually work for the very most important use case!
</p>

<blockquote><pre>
auto i = unordered_set_of_string.find("a string literal used to look up a std::string");
</pre></blockquote>

<p>
And without having to actually construct a <code>std::string</code>!
</p>

<p>
Note that <a href="#hash_append_rules">rules 1 and 2</a> have effectively been expanded to
heterogeneous <code>operator==</code> here.  Since we can compare
<code>string</code>s and <code>char[N]</code>, and it has the obvious meaning,
it also makes sense to message them to a <code>Hasher</code> in such a way that
follows these two rules.
</p>

<a name="hash_combine"></a><h3>Wait a minute.  Isn't <code>hash_append</code> the same thing as
<code>boost::hash_combine</code>?</h3>

<p>No!</p>

<p>
<code>boost::hash_combine</code> is used to combine an already computed hash
code with an object that is to be hashed with <code>boost::hash&lt;T&gt;</code>
(and this is also the 
<a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n3876.pdf">N3876</a>
<code>hash_combine</code>, modulo using <code>std::hash&lt;T&gt;</code>).
</p>
<p>
The 
<a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2012/n3333.html">N3333</a>
<code>hash_combine</code> takes two objects, hashes both of them with
<code>std::hash&lt;T&gt;</code>, and combines those two hash codes into one.
</p>

<p>
In contrast <code>hash_append</code> is used to expose an object's <i>hashable
state</i> to an <b>arbitrary</b> hashing algorithm.  It is up to the generic
hashing algorithm to decide how to combine later bytes with earlier bytes.
</p>


<a name="serialization"></a><h3>Wait a minute.  Isn't <code>hash_append</code> the same thing as
serialization?</h3>

<p>
It is very closely related.  Close enough that there may be a way to elegantly
combine the two.  Each type can expose its state to a <code>Hasher</code> or
<code>Serializer</code>.  However there <i>are</i> differences.  IEEE floating
point is our poster-child for the difference.  For hashing, IEEE floating point
needs to hide the difference between -0. and 0.  For serialization one needs to
keep these two values distinct.  Combining these two functions, for now, remains
beyond the scope of this paper.
</p>

<a name="variadic"></a><h3>Is there a variadic version of <code>hash_append</code>?</h3>

<p>
Yes, this is easily written as:
</p>

<blockquote><pre>
template &lt;class Hasher, class T0, class T1, class ...T&gt;
inline
void
hash_append (Hasher&amp; h, T0 const&amp; t0, T1 const&amp; t1, T const&amp; ...t) noexcept
{
    hash_append (h, t0);
    hash_append (h, t1, t...);
}
</pre></blockquote>

<p>
This allows <code>hash_append</code> for X (for example) to be rewritten as:
</p>

<blockquote><pre>
template &lt;class Hasher&gt;
friend void hash_append(Hasher&amp; h, X const&amp; x) noexcept
{
    using std::hash_append;
    hash_append(h, x.date_, x.data_);
}
</pre></blockquote>

<a name="adapt_algorithm"></a><h3>How easily can algorithms other than FNV-1a be used?</h3>

<p>
Algorithms such as
<a href="https://code.google.com/p/cityhash/">CityHash</a> are not efficiently
adapted to this infrastructure, because as currently coded, CityHash actually
hashes the end of the buffer first.  However
<a href="http://burtleburtle.net/bob/hash/spooky.html">SpookyHash</a>, which
is reported to have quality comparable to CityHash is trivial to incorporate:
</p>

<blockquote><pre>
#include "SpookyV2.h"

class spooky
{
    SpookyHash state_;
public:
    using result_type = std::size_t;

    spooky(std::size_t seed1 = 1, std::size_t seed2 = 2) noexcept
    {
        state_.Init(seed1, seed2);
    }

    void
    operator()(void const* key, std::size_t len) noexcept
    {
        state_.Update(key, len);
    }

    explicit
    operator result_type() noexcept
    {
        std::uint64_t h1, h2;
        state_.Final(&amp;h1, &amp;h2);
        return h1;
    }

};
</pre></blockquote>

<p>
Indeed, this has become our algorithm of choice:
</p>

<blockquote><pre>
template &lt;class Hasher = spooky&gt; struct uhash;
</pre></blockquote>

<p>
<a href="https://131002.net/siphash/">SipHash</a> and the cryptographic
algorithms of the <a href="http://en.wikipedia.org/wiki/SHA-2">SHA-2 family</a>
are also efficiently adaptable to this framework.
</p>

<a name="switch_algorithm"></a><h3>What is involved in switching hashing algorithms?</h3>

<p>
Given the class X shown above, with its complex state distributed among at
least two different contiguous chunks of memory, and potentially many more
if the container switched from <code>vector</code> to <code>deque</code> or
<code>list</code>, one can create an unordered container with the default
hash function like so:
</p>

<blockquote><pre>
std::unordered_set&lt;X, std::uhash&lt;&gt;&gt; my_set;
</pre></blockquote>

<p>
If one instead wanted to specify FNV-1a, the code is easily modified to:
</p>

<blockquote><pre>
std::unordered_set&lt;X, std::uhash&lt;fnv1a&gt;&gt; my_set;
</pre></blockquote>

<p>
This would change the hash code algorithm for every <code>vector</code>,
every <code>deque</code>, every <code>string</code>, every <code>char</code>,
every <code>int</code>, etc. for which X considered part of its hash-worthy state.
That is, hashing algorithms are controlled at the top of the data structure
chain, at the point where the client (e.g. <code>unordered_map</code>) asks for
the hash.  It is not controlled at all down at the bottom of the data structure
chain.  I.e. <code>int</code> has no clue how to hash itself.  It only knows
what state needs to be exposed to a hashing algorithm.
</p>

<p>
And there is no combining step.  The hash algorithm works identically as
if you had copied all of the various discontiguous chunks of state into
one big contiguous chunk of memory, and fed that one big chunk to the
hash algorithm.
</p>

<p>
If one wants to use <code>spooky</code> instead, simply change in <b>one</b>
place:
</p>

<blockquote><pre>
std::unordered_set&lt;X, std::uhash&lt;<b>spooky</b>&gt;&gt; my_set;
</pre></blockquote>

<p>
If a new hashing algorithm is invented tomorrow, and you want to use it, all
that needs to be done is to write an adaptor for it:
</p>

<blockquote><pre>
class new_hash_function
{
public:
    using result_type = std::size_t;

    new_hash_function() noexcept;

    void
    operator()(void const* key, std::size_t len) noexcept;

    explicit
    operator result_type() noexcept;
};
</pre></blockquote>

<p>
And then use it:
</p>

<blockquote><pre>
std::unordered_set&lt;X, std::uhash&lt;<b>new_hash_function</b>&gt;&gt; my_set;
</pre></blockquote>

<p>
You do not need to revisit the <code>hash_append</code> for X, nor for any
of X's sub-types.  The the N hashing algorithms x M sub-types problem has
been solved!
</p>

<a name="pimpl"></a><h3>How does one <code>hash_append</code>
<a href="http://en.wikipedia.org/wiki/Pimpl#C.2B.2B">Pimpl</a> designs?</h3>

<p>
So far, every <code>hash_append</code> function shown must be templated on
<code>Hasher</code> so as to handle any hashing algorithm requested by some
unknown, far away client.  But with the 
<a href="http://en.wikipedia.org/wiki/Pimpl#C.2B.2B">Pimpl</a> design, one
can not send a templated <code>Hasher</code> past the implementation firewall.
</p>

<p>
Or can you ... ?
</p>

<p>
With a combination of <code>std::function</code> and <code>std::ref</code> one
can <i>type erase</i> the templated <code>Hasher</code>, adapting it to a type
with a concrete type, and pass that concrete <code>Hasher</code> through the
implementation firewall.  Imagine a class as shown
<a href="http://en.wikipedia.org/wiki/Pimpl#C.2B.2B">here</a>.
Here is how it can support arbitrary hash algorithms with the proposed
infrastructure:
</p>

<blockquote><pre>
class Handle
{
    struct CheshireCat;               // Not defined here
    CheshireCat* smile;               // Handle

public:
    // Other operations...

    // Hash support
    using type_erased_Hasher = std::function&lt;void(void const*, std::size_t)&gt;;

    friend
    void
    hash_append(type_erased_Hasher, CheshireCat const&amp;);

    template &lt;class Hasher&gt;
    friend
    void
    hash_append(Hasher&amp; h, Handle const&amp; x)
    {
        using std::hash_append;
        if (x.smile == nullptr)
            hash_append(h, nullptr);
        else
            hash_append(type_erased_Hasher(std::ref(h)), *x.smile);
    }
};
</pre></blockquote>

<p>
So you still have to implement a templated <code>hash_append</code> for
<code>Handle</code>, but the implementation of that function forwards to a
<b>non-template</b> function which can be implemented in the source, within
the definition of <code>CheshireCat</code>:
</p>

<blockquote><pre>
friend
void
hash_append(Handle::type_erased_Hasher h, CheshireCat const&amp; c)
{
    using std::hash_append;
    hash_append(h, c.data1_, c.data2_, <i>etc.</i> ...);
}
</pre></blockquote>

<p>
Besides the type of the <code>Hasher</code>, <code>hash_append</code> for
<code>CheshireCat</code> looks just like any other <code>hash_append</code>.
</p>

<p>
Think about what has just happened here.  You've compiled CheshireCat.cpp today.
 And <i>tomorrow</i>, when somebody invents a brand new hash algorithm, your
CheshireCat.cpp uses it, with no re-compile necessary, for the cost of a virtual
function call to the <code>Hasher</code>.  And yet no other client of this new
<code>Hasher</code> (outside of those called by <code>CheshireCat</code>), is
forced to access the new hashing algorithm via a virtual function call. That
borders on magic!
</p>

<p>
It is this very concern (hashing of Pimpl's) that decided the name of the
member function of <code>Hasher</code>s which appends state to the hash
algorithm:
</p>

<blockquote><pre>
void operator()(void const* key, std::size_t len) noexcept;
</pre></blockquote>

<p>
Had this member function been given any other name, such as:
</p>

<blockquote><pre>
void append(void const* key, std::size_t len) noexcept;
</pre></blockquote>

<p>
then programmers would not be able to use <code>std::function</code> to
create a type-erased wrapper around a templated <code>Hasher</code>.
</p>

<a name="seeding"></a><h3>How does one apply random seeding?</h3>

<p>
Many hash algorithms can be randomly seeded during the initialization stage in
such a way that the hash code produced for a type is constant between
invocations by a single client (just like a non-seeded algorithm), but varies
between clients. The variance might be per-process, but could also be as
frequent as per-hash-functor construction, excluding copy or move construction.
In the latter case one might have two distinct <code>unordered_set</code>s
(for example) of the same type, and even containing the same data, and yet have
the two containers result in different hash codes for the same values.  Doing
so can help harden an application from attacks when the application must hash
keys supplied by an untrusted source.
</p>

<p>
This is remarkably easily done with this proposal.  One codes <i>one</i> new
hash functor, which can be used with <i>any</i> <code>Hasher</code> which
accepts a seed, and for <i>any</i> type which already has <code>hash_append</code>
implemented (even those <code>CheshireCat</code>s which have already been
compiled, and can not be recompiled).
</p>

<p>
Here is one possible implementation:
</p>

<blockquote><pre>
template &lt;class Hasher = spooky&gt;
class hardened_hash
{
    std::size_t seed_;
    static std::mt19937_64 rand_s;

public:
    using result_type = typename Hasher::result_type;

    hardened_hash() noexcept : seed_(rand_s()) {}
    explicit hardened_hash(std::size_t seed) noexcept
        : seed_(seed)
    {}

    template &lt;class T&gt;
    result_type
    operator()(T const&amp; t) const noexcept
    {
        Hasher h(seed_);
        using std::hash_append;
        hash_append(h, t);
        return static_cast&lt;result_type&gt;(h);
    }
};
</pre></blockquote>

<p>
In this example, the hashing algorithm is initialized with a random seed when
<code>hardened_hash</code> is default constructed.  Or it can also be given a
deterministic seed by the client at construction time.  In either case, once
constructed, the seed does not change except through hash functor assignment.
</p>

<p>
The same seed is used to initialize the algorithm on each hash functor
invocation. The seeded algorithm is then used to hash the entire message of the
type <code>T</code>, even down to the scalars embedded in <code>T</code> or the
sub-types of <code>T</code>.  Now one simply uses the hash functor:
</p>

<blockquote><pre>
unordered_set&lt;string, hardened_hash&lt;&gt;&gt; set1;  // randomly seeded, Spooky algorithm

// deterministically seeded, FNV-1a algorithm
constexpr size_t num_buckets = 1024;
constexpr size_t seed = 23;
unordered_set&lt;string, hardened_hash&lt;fnv1a&gt;&gt; set2(num_buckets, hardened_hash&lt;fnv1a&gt;{seed});
</pre></blockquote>

<p>
One uses the same technique to apply
<a href="http://en.wikipedia.org/wiki/Salt_(cryptography)">salting</a>,
or <a href="http://en.wikipedia.org/wiki/Padding_(cryptography)">padding</a>
to a type to be hashed.  E.g. one would prepend and/or append the
<a href="http://en.wikipedia.org/wiki/Salt_(cryptography)">salt</a> or
<a href="http://en.wikipedia.org/wiki/Padding_(cryptography)">padding</a>
to the message of <code>T</code> by using additional calls to
<code>hash_append</code> in the <code>operator()(T const&amp; t)</code> of the
hash functor.
</p>

<a name="testing"></a><h3>How much does this cost, in terms of speed and
hash quality, compared to the current N x M method of custom hash functor
implementation?</h3>
<!-- 
<a name="testing"></a><h3>How does the quality of the resulting hash codes compare to the
<code>hash_combine</code> solution?</h3>
 -->

<p>
To answer this question X has been given a randomized default constructor:
</p>

<blockquote><pre>
std::mt19937_64 eng;

X::X()
{
    std::uniform_int_distribution&lt;short&gt; yeardata(1900, 2014);
    std::uniform_int_distribution&lt;unsigned char&gt; monthdata(1, 12);
    std::uniform_int_distribution&lt;unsigned char&gt; daydata(1, 28);
    std::uniform_int_distribution&lt;std::size_t&gt; veclen(0, 100);
    std::uniform_int_distribution&lt;int&gt; int1data(1, 10);
    std::uniform_int_distribution&lt;int&gt; int2data(-3, 5000);
    std::get&lt;0&gt;(date_) = yeardata(eng);
    std::get&lt;1&gt;(date_) = monthdata(eng);
    std::get&lt;2&gt;(date_) = daydata(eng);
    data_.resize(veclen(eng));
    for (auto&amp; p : data_)
    {
        p.first = int1data(eng);
        p.second = int2data(eng);
    }
}
</pre></blockquote>

<p>
Given this, one can easily create a great number of random X's and specify any
hash algorithm.  One can also use the "Solution 2" N x M algorithm outlined
early in this paper.  These two approaches are compared, using several different
hashing algorithms.  Again, note that there is nothing in this proposal which in
any way impedes a programmer from implementing "Solution 2" for any hashing
algorithm of his choice.  This proposal simply gives the programmer an
alternative that takes O(N) implementation work, instead of O(N*M)
implementation work, to support N hashing algorithms.
</p>

<p>
The hash function quality tester suite used herein is basic. The first test,
<code>test1</code>, looks at each 64 bit hash code as a collection of 16
hex-digits.  The expectation is that each hex-digit should be roughly equally
represented in each hexadecimal place of the hash code.  The test returns
maximum deviation of the average, from the expected average.
</p>

<p>
The second test is
<a href="https://code.google.com/p/smhasher/wiki/Distribution">TestDistribution</a>
gratefully borrowed from the
<a href="https://code.google.com/p/smhasher/wiki/SMHasher">smhasher</a>
test suite.
</p>

<p>
A million hash codes are generated from a million randomized but unique X's,
randomized by a default constructed <code>std::mt19937_64</code>, and fed to
these two tests.  For each test, the smaller the result the better.
</p>

<blockquote>
<table border="1" cellpadding="5">
<caption>Contiguous Test Results -- smaller is better</caption>
<tr>
<th></th><th></th> <th>test 1</th> <th>test 2</th> <th>total time (sec)</th>
</tr>
<tr>
<th rowspan=2>FNV-1a</th><th>N x M</th> <td>0.012448</td><td>0.00630771</td> <td>0.81771s</td>
</tr>
<tr>
<th>uhash</th><td>0.0104</td> <td>0.00117008</td> <td>0.806777s</td>
</tr>
<tr>
<th rowspan=2>Jenkins 1</th><th>N x M</th> <td>0.013056</td><td>0.0247747</td> <td>1.08094s</td>
</tr>
<tr>
<th>uhash</th><td>0.0134789</td> <td>0.000733134</td> <td>1.09616s</td>
</tr>
<tr>
<th rowspan=2>Spooky V2</th><th>N x M</th> <td>0.015072</td><td>0.00106153</td> <td>0.569262s</td>
</tr>
<tr>
<th>uhash</th><td>0.011536</td><td>0.0012386</td> <td>0.642032s</td>
</tr>
<tr>
<th rowspan=2>CityHash</th><th>N x M</th> <td>0.0119027</td><td>0.00122526</td> <td>0.381s</td>
</tr>
<tr>
<th>uhash</th><td>0.010128</td><td>0.00111908</td> <td>2.53071s</td>
</tr>
</table>
</blockquote>

<p>
The above table shows that the clear speed winner is CityHash, but only when
implemented with effort O(N*M).  When implemented with <code>uhash</code>,
the implementation is very slow because for this algorithm, the entire hashable
state must be copied into a temporary buffer prior to the hashing computation.
</p>

<p>
This is a remarkable accomplishment in speed, especially when compared to the
far simpler FNV-1A algorithm, which clocks in over 2X slower.  The downside is
that it is very difficult for the average programmer to guarantee that CityHash
is being used for every hash computation.
</p>

<p>
Using SpookyHash, combined with <code>uhash</code>, the programmer can achieve
just as high a quality as CityHash, and with 26% better performance than the
far simpler FNV-1A, but still 69% slower than the labor intensive CityHash
solution.  Because of the use of <code>uhash</code>, the programmer can achieve
this with very little programming effort, compared to what is required for
implementing CityHash with the N x M technique.
</p>

<p>
This test played towards CityHash's and Spooky's strengths:  very long
contiguous keys.  If we slightly modify X as earlier described such that
the <code>tuple</code> and <code>vector::value_type</code> are no longer
contiguously hashable, the results change fairly dramatically:
</p>

<blockquote>
<table border="1" cellpadding="5">
<caption>Non-Contiguous Test Results -- smaller is better</caption>
<tr>
<th></th><th></th> <th>test 1</th> <th>test 2</th> <th>total time (sec)</th>
</tr>
<tr>
<th rowspan=2>FNV-1a</th><th>N x M</th> <td>0.013424</td><td>0.0698351</td> <td>0.537677s</td>
</tr>
<tr>
<th>uhash</th><td>0.0115742</td> <td>0.00121977</td> <td>0.608181s</td>
</tr>
<tr>
<th rowspan=2>Jenkins 1</th><th>N x M</th> <td>0.013968</td><td>0.082919</td> <td>0.672917s</td>
</tr>
<tr>
<th>uhash</th><td>0.00928075</td> <td>0.00155438</td> <td>0.828472s</td>
</tr>
<tr>
<th rowspan=2>Spooky V2</th><th>N x M</th> <td>0.0101182</td><td>0.00142344</td> <td>1.51985s</td>
</tr>
<tr>
<th>uhash</th><td>0.0136</td><td>0.00114236</td> <td>1.2635s</td>
</tr>
<tr>
<th rowspan=2>CityHash</th><th>N x M</th> <td>0.011904</td><td>0.000966045</td> <td>0.851983s</td>
</tr>
<tr>
<th>uhash</th><td>0.013072</td><td>0.000903772</td> <td>2.16299s</td>
</tr>
</table>
</blockquote>

<p>
Now the speed test winner is the N x M implementation of FNV-1A, however the
quality of the resulting hash is questionable by test 2.  If we pay a 13%
performance penalty to get to the 2nd fastest hasher, we get a large boost in
hash code quality, large enough that it can be considered about as good as any
of the other results.  And this is the easy-to-implement FNV-1A implementation
using <code>uhash</code>, clocking in at 40% faster than CityHash, and
interestingly, 32% faster than the same <code>uhash</code>-based solution for
the "contiguous" results.  I.e. This test plays towards the strength of the
small, simple hashing algorithms.  But the "combining step", when used in the N x
M technique, significantly degrades the quality of these simple algorithms.
</p>

<p>
Overall, for any specific hashing algorithm except for CityHash which requires a
temporary dynamic buffer, the speed cost of using <code>uhash</code> over the N
x M technique varies from being a little more expensive (for the simpler
algorithms - FNV-1A, Jenkins 1), to a little less expensive for the more
complex' algorithms (Spooky).  And the quality of the resulting hash codes is
never significantly degraded when moving from N x M to <code>uhash</code> and is
sometimes significantly improved.
</p>

<p>
CityHash suffers significantly in the speed department when moving to
<code>uhash</code> because it does not process its bytes in order like the
other algorithms.  If CityHash could be re-implemented to process its bytes in
order, that would make a most interesting hashing algorithm when combined with
the easy-to-implement <code>uhash</code>.
</p>

<p>
For completeness, here are the same tests results for just calling
<code>std::hash</code> as shown in "Solution 1".  The speed is very good, but
the quality is very bad. These results, both speed and quality, are very
implementation dependent.  These results are obtained on libc++, where the
<code>std::hash&lt;integral&gt;</code> is as fast as it can get:  it is the
identity function.  This explains both the high speed, and the low quality.  The
gcc libstdc++ also uses the identity function for integral hashes.  VC++ does
not. It would likely have both slower performance and higher hash quality,
though this test has not been run.
</p>

<blockquote>
<table border="1" cellpadding="5">
<caption><code>std::hash</code> Test Results -- smaller is better</caption>
<tr>
<th></th> <th>test 1</th> <th>test 2</th> <th>total time (sec)</th>
</tr>
<tr>
<th>std::hash</th> <td>0.270544</td><td>0.961271</td> <td>0.462652s</td>
</tr>
</table>
</blockquote>

<a name="Summary"></a><h2>Summary</h2>

<p>
This paper presents an infrastructure that decouples types from hashing
algorithms.  This decoupling has several benefits:
</p>

<ul>
<li>Clients can very easily switch hashing algorithms used by
very complex data structures, thus enabling comparisons as shown
in the previous section.</li>
<li>Hash algorithm designers can concentrate on designing better hash
algorithms, with little worry about how these new algorithms can be
incorporated into existing code.</li>
<li>Type designers can create their hash support just once, without
worrying about what hashing algorithm should be used.</li>
<li>Clients can easily adopt most existing algorithms to this proposed
infrastructure.</li>
<li>The resulting hash codes are a true reflection of the original design
of the hashing algorithms, even though applied to complex data structures
spanning discontiguous memory.</li>
</ul>

<a name="proposedinfrastructure"></a><h3>Summary of proposed infrastructure</h3>

<blockquote><pre>
template &lt;class T&gt; struct is_contiguously_hashable;                        // A type property trait
template &lt;class Hasher&gt; void hash_append(Hasher&amp; h, T const&amp; t) noexcept;  // overloaded for each type T
template &lt;class Hasher = <i>unspecified-default-hasher</i>&gt; struct uhash;         // A hashing functor
</pre></blockquote>

<a name="debugHasher"></a><h2>Appendix A: <code>debugHasher</code></h2>

<p>
Another interesting "hash algorithm" is <code>debugHasher</code>.  This is a
small utility that can be used to help type authors debug their
<code>hash_append</code> function.  This utility is not proposed.  It is simply
presented herein to illustrate the utility of this overall hashing infrastructure
design.
</p>

<blockquote><pre>
#include &lt;iostream&gt;
#include &lt;iomanip&gt;
#include &lt;vector&gt;

class debugHasher
{
    std::vector&lt;unsigned char&gt; buf_;
public:
    using result_type = std::size_t;

    void
    operator()(void const* key, std::size_t len) noexcept
    {
        unsigned char const* p = static_cast&lt;unsigned char const*&gt;(key);
        unsigned char const* const e = p + len;
        for (; p &lt; e; ++p)
            buf_.push_back(*p);
    }

    explicit
    operator std::size_t() noexcept
    {
        std::cout &lt;&lt; std::hex;
        std::cout &lt;&lt; std::setfill('0');
        unsigned int n = 0;
        for (auto c : buf_)
        {
            std::cout &lt;&lt; std::setw(2) &lt;&lt; (unsigned)c &lt;&lt; ' ';
            if (++n == 16)
            {
                std::cout &lt;&lt; '\n';
                n = 0;
            }
        }
        std::cout &lt;&lt; '\n';
        std::cout &lt;&lt; std::dec;
        std::cout &lt;&lt; std::setfill(' ');
        return buf_.size();
    }
};
</pre></blockquote>

<p>
<code>debugHasher</code> is a fake "hashing algorithm" that does nothing but
collect the bytes sent to a hash by the entire collection of the calls to
<code>hash_append</code> made by a key and all of its sub-types.  The collection
of bytes is output to <code>cout</code> when the hasher is converted to its
<code>result_type</code>.
</p>

<p>
As can be readily seen, it is not difficult to create such a debugging tool.  It
is then used, just as easily:
</p>

<blockquote><pre>
std::vector&lt;std::vector&lt;std::pair&lt;int, std::string&gt;&gt;&gt; v {{{1, "abc"}},
                                                         {{2, "bca"}, {3, "cba"}},
                                                         {}};
std::cout &lt;&lt; uhash&lt;debugHasher&gt;{}(v) &lt;&lt; '\n';
</pre></blockquote>

<p>
Assuming a 32 bit <code>int</code>, 64 bit <code>size_t</code>, and little
endian, this will reliably output:
</p>

<blockquote><pre>
01 00 00 00 61 62 63 00 01 00 00 00 00 00 00 00 
02 00 00 00 62 63 61 00 03 00 00 00 63 61 62 00 
02 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 
03 00 00 00 00 00 00 00 
56
</pre></blockquote>

<p>
The last line is simply the number of bytes that have been sent to the
<code>Hasher</code>.  The first 4 lines are those bytes, formatted as two hex
digits per byte, with bytes separated by a space, and 16 bytes per line for
readability.  If one carefully inspects this byte stream and compares it to the
data structure which has been "hashed", and to the proposed
<code>hash_append</code> above for <code>vector</code>, <code>string</code> and
<code>pair</code>, one can verify that the byte stream is consistent with the
specification.
</p>

<p>
Improving <code>debugHasher</code> to collect useful statistics such as the
number of times called, and the average number of bytes hashed per call, is left
as a fun exercise for the reader.
</p>

<a name="Acknowledgments"></a><h2>Acknowledgments</h2>

<p>
Special thanks to John Bytheway for pointing out the real-world utility of 
naming the "append" member of <code>Hasher</code> to <code>operator()</code>
in order to accommodate code which can't call <code>hash_append</code> from a
header.
</p>

<p>
Thanks to Daniel James (et al.) for highlighting the problem of hashing
zero-length containers with no message.
</p>

<p>
Thanks to Dix Lorenz (et al.) for pointing out that the <code>result_type</code> of the
<code>Hasher</code> need not be <code>size_t</code>, and indeed, can not be
if we want this infrastructure to fully handle cryptographic hash functions
(which produce results larger than a <code>size_t</code>).
</p>

<p>
Additional thanks to Walter Brown and Richard Smith for their invaluable review
and guidance.
</p>

<p>
This research has been generously supported by <a
href="https://www.ripplelabs.com">Ripple Labs</a>.  We would especially like to
thank our colleagues on the RippleD team.
</p>

</body>
</html>
