<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
        "http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
	<title>Types Don't Know #</title>

	<style>
	p {text-align:justify}
	li {text-align:justify}
	blockquote.note
	{
		background-color:#E0E0E0;
		padding-left: 15px;
		padding-right: 15px;
		padding-top: 1px;
		padding-bottom: 1px;
	}
	ins {color:#00A000}
	del {color:#A00000}
	</style>
</head>
<body>

<address align=right>
<br/>
<br/>
<a href="mailto:howard.hinnant@gmail.com">Howard E. Hinnant</a><br/>
<a href="mailto:vinnie.falco@gmail.com">Vinnie Falco</a><br/>
2014-04-01
</address>
<hr/>
<h1 align=center>Types Don't Know #</h1>

<h2>Introduction</h2>

<p>
This paper starts with an assertion:
</p>

<blockquote class=note><p>
Types should not know how to hash themselves.
</p></blockquote>

<p>
The rest of this paper begins with demonstrating the problems created when
software systems assume that types do know how to hash themselves, and what
can be done to solve these problems.
</p>

<h2>The Example</h2>

<p>
Instead of starting with a basic example like <code>std::string</code> or
<code>int</code>, this paper will introduce an example class X
that is meant to be representative of a type that a programmer would write,
and would want to create a hash code for:
</p>

<blockquote><pre>
class X
{
    std::tuple&lt;short, unsigned char, unsigned char&gt; date_;
    std::vector&lt;std::pair&lt;int, int&gt;&gt; data_;

public:
    X();
    // ...
};
</pre></blockquote>

<blockquote class=note><p>
How do we write the hash function for X?
</p></blockquote>

<h3>Solution 1: Specialize <code>std::hash&lt;X&gt;</code></h3>

<p>
If we standardize
<a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n3876.pdf">N3876</a>
which gives us <code>hash_combine</code> and <code>hash_val</code> from
<a href="http://www.boost.org/doc/libs/1_55_0/doc/html/hash/combine.html">boost</a>,
then this is relatively doable:
</p>

<blockquote><pre>
namespace std
{

template &lt;&gt;
struct hash&lt;X&gt;
{
    size_t
    operator()(X const&amp; x) const noexcept
    {
        size_t h = 0;
        std::hash_combine (h, std::hash_val(std::get&lt;0&gt;(x.date_)
                                          , std::get&lt;1&gt;(x.date_)
                                          , std::get&lt;2&gt;(x.date_)));
        for (auto const&amp; p : x.data_)
            std::hash_combine (h, std::hash_val(p.first, p.second));
        return h;
    }
};

}  // std
</pre></blockquote>

<p>
And we also need to add a <code>friend</code> statement to our class X:
</p>

<blockquote><pre>
friend class std::hash&lt;X&gt;;
</pre></blockquote>

<p>
Now we can say <code>std::hash&lt;X&gt;{}(x)</code> and we get back a
hash code.  Is it a <i>good</i> hash code? <i>&lt;shrug&gt;</i>.  The
quality of the hash code is unknown.  What hashing algorithm has been
used? <i>&lt;shrug&gt;</i>.  The hashing algorithm is unspecified.  Later
in this paper I will try to at least partially answer these questions.
</p>

<p>
Ok, what if we can't leave things up to chance?  We want to use a 
hashing algorithm that is known to have some given verifiable
qualities.  How do we do that?
</p>

<h3>Solution 2: Make use of a well-known hashing algorithm</h3>

<p>
There are many hash algorithms freely available, and several of them explored
in <a href="http://blog.aggregateknowledge.com/2011/12/29/choosing-a-good-hash-function-part-2/">this blog</a>.
Which of these algorithms should we use?  Assuming we pick one, how do we
use that algorithm?  As a simple example, let's assume that we wish to use
<a href="http://www.isthe.com/chongo/tech/comp/fnv/index.html">FNV-1a</a>
which can be coded up like this:
</p>

<blockquote><pre>
std::size_t
fnv1a (void const* key, std::size_t len)
{
    unsigned char const* p = static_cast&lt;unsigned char const*&gt;(key);
    unsigned char const* const e = p + len;
    std::size_t h = 14695981039346656037u;
    for (; p &lt; e; ++p)
        h = (h ^ *p) * 1099511628211u;
    return h;
}
</pre></blockquote>

<p>
I have picked FNV-1a, not because it is a terribly good hash algorithm.  It is
just ok.  There are much better ones.  I've picked it because it is very
simple.
</p>

<p>
If we are willing to assume that there are no padding bits in
<code>std::pair&lt;int, int&gt;&gt;</code> we could first hash
the entire <code>vector</code> with one call to <code>fnv1a</code>:
</p>

<blockquote><pre>
std::size_t h1 = fnv1a (data_.data(), data_.size() * sizeof(std::pair&lt;int, int&gt;&gt;);
</pre></blockquote>

<p>
It isn't the prettiest code in the world.  But it will work.  And if we dare
to make the same (no padding) assumptions about <code>date_</code> we could
write similar code there:
</p>

<blockquote><pre>
std::size_t h2 = fnv1a (&date_, sizeof(date_));
</pre></blockquote>

<p>
Now we just need to combine these two hash function results into one.  And this
is where things get complicated.  And this is the point on which the assumption
that types know how to hash themselves begins to fall apart.
</p>

<p>
What about using the proposed <code>std::hash_combine</code> you rightly ask?
</p>

<p>
That might look something like this:
</p>

<blockquote><pre>
std::size_t h1 = fnv1a (data_.data(), data_.size() * sizeof(std::pair&lt;int, int&gt;&gt;);
std::hash_combine (h1, date_);
return h1;
</pre></blockquote>

<p>
But this doesn't really work.  Internally <code>std::hash_combine</code>
calls <code>std::hash&lt;std::tuple&lt;short, unsigned char, unsigned char&gt;&gt;{}(date_)</code>,
and we don't want to call <code>std::hash</code>.  We don't know what that
code does.  We want to call <code>fnv1a</code>.  And we can't specialize
<code>std::hash</code> to do what we want because we don't "own" any parts
of the type that we want to specialize on (<code>std::tuple</code> and
<code>char</code>).
</p>

<p>
The very best we can do is crib the algorithm from <code>std::hash_combine</code>
is based on.  We can put the entire thing in a <code>std::hash&lt;X&gt;</code>
specialization as shown before:
</p>

<blockquote><pre>
namespace std
{

template &lt;&gt;
struct hash&lt;X&gt;
{
    size_t
    operator()(X const&amp; x) const noexcept
    {
        std::size_t h = fnv1a (&amp;x.date_, sizeof(x.date_));
        std::size_t h2 = fnv1a (x.data_.data(),
                                    x.data_.size()*sizeof(std::pair&lt;int, int&gt;));
        h ^= h2 + 0x9e3779b9 + (h&lt;&lt;6) + (h&gt;&gt;2);
        return h;
    }
};

}  // std
</pre></blockquote>

<p>
By now there should be several alarms going off in your head:
</p>

<ol>
<li>How sure are we that there are no padding bits in <code>pair</code>
and <code>tuple</code>?</li>

<li>That mixing step looks suspicious.  Does it really work for 64 bit
hash codes?</li>

<li>Because of the combining step, this really is no longer FNV-1a.  My
result will likely no longer have the known properties of FNV-1a.  Thus
my original goal of using FNV-1a has been compromised.</li>

<li>If I can't assume no-padding, and/or if I'm using a container
that is not contiguous, then I won't have just one combining step.
I'll have tons of them.  The combining step will then dominate the hashing
algorithm.  Then I'm clearly not using FNV-1a.  I'm using whatever
that combining step is doing.</li>
</ol>

<p>
The importance of this last point can not be understated.  Good hash
algorithms are notoriously difficult to write, and poor ones notoriously
easy.  This combining step has been pulled from a
<a href="http://goanna.cs.rmit.edu.au/~jz/fulltext/jasist-tch.pdf">paper whose
focus was not investigating the quality of this algorithm</a>.
</p>

<p>
Backing up...
</p>

<p>
I do not want to use:
</p>

<blockquote><pre>
seed ^= hash(v) + 0x9e3779b9 + (seed&lt;&lt;6) + (seed&gt;&gt;2);
</pre></blockquote>

<p>
I want to use
<a href="http://www.isthe.com/chongo/tech/comp/fnv/index.html">FNV-1a</a>,
or
<a href="https://code.google.com/p/smhasher/wiki/MurmurHash3">MurmurHash3</a>,
or
<a href="https://code.google.com/p/cityhash/">CityHash</a>,
or
<a href="http://burtleburtle.net/bob/hash/spooky.html">SpookyHash</a>,
or whatever.  Every time I "dilute" one of these hash algorithms by using
a combining step of unknown quality, I dilute the confidence I have in the
final hash code I am producing.
</p>

<p>
Essentially, with the inclusion of:
</p>

<blockquote><pre>
seed ^= hash(v) + 0x9e3779b9 + (seed&lt;&lt;6) + (seed&gt;&gt;2);
</pre></blockquote>

<p>
in the computation of the hash code for X, I'm giving too much knowledge
about the hashing process to the author of X.  Indeed, even hardcoding calls
to <code>fnv1a</code> into this code is not scalable.  Imagine I have a
sizable program with hundreds, even thousands of types that need hash functions
written for them.  Changing from FNV-1a to MurmurHash3 or SpookyHash becomes
a massive amount of error-prone work.  Each type must be revisited to change
which algorithm it is using to produce its hash code.
</p>

<p>
It would certainly be possible to have each type provide a variety of hash
code algorithms.  But as most types are composed of other types, which are
further composed of other types in other libraries, and so on, down to
scalar types, this also is not a scalable solution.
</p>

<p>
In essence, the type is the wrong place to put knowledge about any given
hash algorithm.  That knowledge belongs in a specialized hashing library.
</p>

<blockquote class=note><p>
Types should not know how to hash themselves.
</p></blockquote>

<p>
The question now becomes:  How do you interface X with an arbitrary hashing
library?
</p>

<h3>How to get X to use a general purpose hashing algorithm</h3>

<p>
Although most modern hashing algorithms are much more complicated than
<code>fnv1a</code> shown above, there are similarities among them.
</p>

<ul>
<li>They generally take a stream of bytes as their input.  This is often
specified as a  <code>void const*</code> and a <code>size_t</code> length.</li>

<li>
This interface implies that they work on a contiguous array of bytes.
</li>

<li>
The algorithms generally have an initialization stage, often taking an
optional seed, followed by an accumulation stage which depends on the
supplied bytes, followed by a finalization stage after all of the bytes
are consumed.
</li>
</ul>

<p>
Not all, but many of the algorithms also have the property that they consume
bytes in the order that they are received, possibly with a fixed sized internal
buffer.  In the FNV-1a example, that internal buffer is reduced down to a
single byte.  This characteristic can be taken advantage of in order to hash
<i>discontiguous</i> memory.
</p>

<p>
For example consider this minor repackaging of the FNV-1a algorithm:
</p>

<blockquote><pre>
class fnv1a
{
    std::size_t state_ = 14695981039346656037u;
public:

    void
    append(void const* key, std::size_t len) noexcept
    {
        unsigned char const* p = static_cast&lt;unsigned char const*&gt;(key);
        unsigned char const* const e = p + len;
        for (; p &lt; e; ++p)
            state_ = (state_ ^ *p) * 1099511628211u;
    }

    explicit
    operator std::size_t() noexcept
    {
        return state_;
    }
};
</pre></blockquote>

<p>
Now the algorithm can be accessed in 3 stages:
</p>

<ol>
<li>The algorithm is initialized in a constructor, in this case the
implicit default constructor.</li>
<li>The algorithm consumes bytes in the <code>append</code> function.
Note that this function can be called any number of times.  In
each call the memory is contiguous.  But there is no requirement at
all that separate calls refer to a single block of memory.</li>
<li>The algorithm is finalized when the object is converted to a 
<code>size_t</code>.  This is the finalization stage, which in this
case is trivial, but could be arbitrarily complex.</li>
</ol>

<p>
We can say that <code>fnv1a</code> meets the requirements of a
<code>Hasher</code>.  A <code>Hasher</code> is a class type that can be
constructed (default, or possibly with seeding), has an <code>append</code>
member function with the signature represented above.  The <code>append</code>
member function processes bytes, updating the internal state of the
<code>Hasher</code>.  This internal state can be arbitrarily complex.  Indeed
an extreme example of internal state could be a copy of every chunk of memory
supplied to the <code>Hasher</code>.  And finally a <code>Hasher</code> can
be explicitly converted to a <code>size_t</code>.
</p>

<b>Introducing the Universal hash function!</b>

<p>
Given the concept of <code>Hasher</code>, a universal hash functor, which
takes <b>any</b> type <code>T</code> can now be written (almost):
</p>

<blockquote><pre>
template &lt;class Hasher&gt;
struct uhash
{
    template &lt;class T&gt;
    std::size_t
    operator()(T const&amp; t) const noexcept
    {
        Hasher h;
        using hash_defaults::hash_append;
        hash_append(h, t);
        return static_cast&lt;std::size_t&gt;(h);
    }
};
</pre></blockquote>

<p>
The <code>Hasher</code> is constructed.  It is appended to using <code>t</code>
as a key.  And then it is explicitly converted to the desired result.  This
<code>hash</code> could even be defaulted to use your favorite hash algorithm:
</p>

<blockquote><pre>
template &lt;class Hasher = fnv1a&gt; struct uhash;
</pre></blockquote>

<b>What is <code>hash_append</code>?</b>

<p>
The <code>hash_append</code> function is the glue that binds the individual
types to the general <code>Hasher</code>.
</p>

<ul>
<li>The <code>Hasher</code> knows nothing about the type <code>T</code>
being hashed.</li>
<li>The hash functor <code>uhash</code> knows nothing about the <code>Hasher</code>,
nor the type <code>T</code> being hashed.</li>
<li>Below I will show how each type <code>T</code> can implement
<code>hash_append</code> (much like a type implements <code>swap</code>), and
yet knows nothing about the <code>hash</code> functor, nor the algorithm
encapsulated in the <code>Hasher</code>.</li>
</ul>

<p>
Each type <code>T</code> is responsible only for exposing its hash-worthy state
to the <code>Hasher</code> in the function  <code>hash_append</code>.
<code>T</code> is <i>not</i> responsible for combining hash codes.  Nor is it
responsible for any hashing arithmetic whatsoever.  It is only responsible for
pointing out where its data is, how many different chunks of data there are,
and what order they should be presented to the <code>Hasher</code>.
</p>

<p>
For example, here is how X would implement <code>hash_append</code>: 
</p>

<blockquote><pre>
class X
{
    std::tuple&lt;short, unsigned char, unsigned char&gt; date_;
    std::vector&lt;std::pair&lt;int, int&gt;&gt; data_;

public:
    X();

    // Hook into the system like this
    template &lt;class Hasher&gt;
    friend void hash_append(Hasher&amp; h, X const&amp; x) noexcept
    {
        using hash_defaults::hash_append;
        hash_append(h, x.date_);
        hash_append(h, x.data_);
    }
}
</pre></blockquote>

<p>
Like <code>swap</code>, <code>hash_append</code> is a customization point
for each type.  Only a type knows what parts of itself it should expose to a
<code>Hasher</code>, even though the type has no idea what algorithm is being
used to do the hashing.  For example <code>std::vector&lt;T, A&gt;</code>
would never expose its <code>capacity()</code>.  Indeed, the <code>hash_append</code>
for <code>std::vector&lt;T, A&gt;</code> should look more like:
</p>

<blockquote><pre>
template &lt;class Hasher, class T, class Alloc&gt;
void
hash_append(Hasher&amp; h, std::vector&lt;T, Alloc&gt; const&amp; v) noexcept
{
    for (auto const&amp; t : v)
        hash_append(h, t);
}
</pre></blockquote>

<p>
And for <code>std::pair&lt;T, U&gt;</code>:
</p>

<blockquote><pre>
template &lt;class Hasher, class T, class U&gt;
void
hash_append (Hasher&amp; h, std::pair&lt;T, U&gt; const&amp; p) noexcept
{
    hash_append (h, p.first);
    hash_append (h, p.second);
}
</pre></blockquote>

<p>
Eventually <code>hash_append</code> will drill down to primitive types such as
<code>int</code>:
</p>

<blockquote><pre>
template &lt;class Hasher&gt;
void
hash_append(Hasher&amp; h, int const&amp; i) noexcept
{
    h.append(&amp;i, sizeof(i));
}
</pre></blockquote>

<p>
Whereupon a contiguous chunk of memory is actually accumulated by the
<code>Hasher</code>.  Recall that the <code>Hasher</code> has a member function
<code>append (const void* key, std::size_t len) noexcept</code>.  And the
<code>int</code> is just a chunk of <i>contiguous</i> memory that is
<i>hashable</i>.  It is now prudent to deeply consider what it means to say
that a type (such as <code>int</code>) is <i>contiguously hashable</i>.
</p>

<p>
A type <code>T</code> is <i>contiguously hashable</i> if for all combinations of
two values of a type, say <code>x</code> and <code>y</code>, if <code>x ==
y</code>, then it must also be true that <code>memcmp(addressof(x),
addressof(y), sizeof(T)) == 0</code>.  I.e. if <code>x == y</code>, then
<code>x</code> and <code>y</code> have the same bit pattern representation. A
2's complement <code>int</code> satisfies this property because every bit
pattern an <code>int</code> can have results in a distinct value.  And there are
no "padding bits" which might take on random values.  This property is necessary
because if two values are equal, then they must hash to the same hash code.
</p>

<b>An Optimization: <code>is_contiguously_hashable&lt;T&gt;</code>:</b>

<p>
With that in mind we can easily imagine a type trait:
</p>

<blockquote><pre>
template &lt;class T&gt; struct is_contiguously_hashable;
</pre></blockquote>

<p>
which derives from either <code>true_type</code> or <code>false_type</code>. And
on 2's complement systems,
<code>is_contiguously_hashable&lt;int&gt;::value</code> is <code>true</code>.
And we might anticipate that some other types, such as <code>char</code> and
<code>long long</code> are also <i>contiguously hashable</i>.  With this
tool we can now easily write <code>hash_append</code> for all contiguously
hashable types:
</p>

<blockquote><pre>
template &lt;class Hasher, class T&gt;
inline
std::enable_if_t
&lt;
    is_contiguously_hashable&lt;T&gt;::value
&gt;
hash_append(Hasher&amp; h, T const&amp; t) noexcept
{
    h.append(addressof(t), sizeof(t));
}
</pre></blockquote>

<p>
Now the task remains to specialize <code>is_contiguously_hashable</code>
properly for those scalars we want to use this implementation of
<code>hash_append</code> for, and for any other scalars, implement
<code>hash_append</code> appropriately.  As an example of the latter, consider
IEEE floating point types.
</p>

<p>
An IEEE floating point type is <i>not contiguously hashable</i> because 
<code>0. == -0.</code> but these two values are represented with different
bit patterns.  Therefore its <code>hash_append</code> must go to extra
effort to ensure that <code>0.</code> and <code>-0.</code> hash to identical
hash codes, but <b>without</b> dictating a specific hash algorithm.  This
could be done like so:
</p>

<blockquote><pre>
template &lt;class Hasher, class T&gt;
inline
std::enable_if_t
&lt;
    std::is_floating_point&lt;T&gt;::value
&gt;
hash_append(Hasher&amp; h, T t) noexcept
{
    if (t == 0)
        t = 0;
    h.append(&amp;t, sizeof(t));
}
</pre></blockquote>

<p>
Class types that are composed of only  <i>contiguously hashable</i> types
and that have no padding bytes, may also be considered to be
<i>contiguously hashable</i>.  For example consider this specialization of
<code>is_contiguously_hashable&lt;std::pair&lt;T, U&gt;&gt;</code>:
</p>

<blockquote><pre>
template &lt;class T, class U&gt;
struct is_contiguously_hashable&lt;std::pair&lt;T, U&gt;&gt;
    : public std::integral_constant&lt;bool, is_contiguously_hashable&lt;T&gt;::value &amp;&amp; 
                                          is_contiguously_hashable&lt;U&gt;::value &amp;&amp;
                                          sizeof(T) + sizeof(U) == sizeof(std::pair&lt;T, U&gt;)&gt;
{
};
</pre></blockquote>

<p>
In English:  If the <code>pair</code>'s two types are both contiguously
hashable, and if the size of the two members is the same size as the
<code>pair</code> (so there are no padding bytes), then the entire
<code>pair</code> itself is contiguously hashable!
</p>

<p>
This same logic can be applied to <code>array</code>, <code>tuple</code>, and
possibly user-defined types as well.  Consequently, a great many types can be
easily and safely classified as contiguously hashable.  This is important because
with modern hash algorithm implementations, the bigger the chunk of contiguous
memory you can send to the <code>Hasher</code> at one time, the higher the
performance (in terms of bytes-hashed/second) the <code>Hasher</code> is likely
to perform.
</p>

<p>
With that in mind (the bigger the memory chunk the better), consider again
<code>hash_append</code> for <code>vector</code>:
</p>

<blockquote><pre>
template &lt;class Hasher, class T, class Alloc&gt;
inline
std::enable_if_t
&lt;
    !is_contiguously_hashable&lt;T&gt;::value
&gt;
hash_append(Hasher&amp; h, std::vector&lt;T, Alloc&gt; const&amp; v) noexcept
{
    for (auto const&amp; t : v)
        hash_append(h, t);
}

template &lt;class Hasher, class T, class Alloc&gt;
inline
std::enable_if_t
&lt;
    is_contiguously_hashable&lt;T&gt;::value
&gt;
hash_append(Hasher&amp; h, std::vector&lt;T, Alloc&gt; const&amp; v) noexcept
{
    h.append (v.data(), v.size()*sizeof(T));
}
</pre></blockquote>

<p>
I.e. if the <code>T</code> <b>is</b> contiguously hashable, then even though
<code>vector</code> itself is not, there can still be a <i>huge</i> optimization
made by having <code>vector</code> send its <i>contiguous</i> <code>data</code>
buffer to <code>hash_append</code>.
</p>

<p>
This optimization can be made without any help from the <code>std::lib</code>.
Other optimizations are possible, but could only be made from within the
<code>std::lib</code>.  For example, what if <code>T</code> is <code>bool</code>
in the above example?  What about <code>deque&lt;T&gt;</code>?  It could hash
its internal contiguous buffers all at once, but there is no way to implement
that without intimate knowledge of the internals of the <code>deque</code>
implementation.  Externally, the best one can do for <code>deque&lt;T&gt;</code>
is to send each individual <code>T</code> to <code>hash_append</code> one at a
time.  This still gives the very same correct answer, just slower.
</p>

<p>
If you believe <b>your type</b> to be contiguously hashable, you should
specialize <code>is_contiguously_hashable&lt;YourType&gt;</code> appropriately,
as has been shown for <code>pair</code>.  This would mean that not only is
hashing <code>YourType</code> optimized, but hashing
<code>vector&lt;YourType&gt;</code>, et. al. is also optimized!
</p>

<b>Strings are really important.  What say ye about strings?</b>

<p>
Like <code>vector</code>, <code>basic_string</code> can be optimized if the
<code>CharT</code> is contiguously hashable, as it will be for any reasonable
<code>CharT</code>.  But there is an interesting and useful wrinkle...
</p>

<p>
C-style arrays are also hashable:
</p>

<blockquote><pre>
template &lt;class Hasher, class T, std::size_t N&gt;
inline
std::enable_if_t
&lt;
    !is_contiguously_hashable&lt;T&gt;::value
&gt;
hash_append(Hasher&amp; h, T (&amp;a)[N]) noexcept
{
    for (auto const&amp; t : a)
        hash_append(h, t);
}
</pre></blockquote>

<p>
And if <code>T</code> <i>is</i> contiguously hashable, then the generic
<code>hash_append</code> works for C-style arrays (as long as we specialize
<code>is_contiguously_hashable&lt;T[N]&gt;</code>) appropriately.  And well,
this is the good part, the decltype(a-string-literal) is a C-style array type.
For string literals, the array type is always one larger than the
<code>strlen</code> of the literal because the array contains the trailing null
character.  And, by happy coincidence, <code>basic_string</code> now always
embeds a trailing null character as well.  So optimized or not, the
<code>hash_append</code> for <code>basic_string</code> should be specified
to include hashing the trailing null character:
</p>

<blockquote><pre>
template &lt;class Hasher, class CharT, class Traits, class Alloc&gt;
inline
std::enable_if_t
&lt;
    is_contiguously_hashable&lt;CharT&gt;::value 
&gt;
hash_append(Hasher&amp; h, std::basic_string&lt;CharT, Traits, Alloc&gt; const&amp; s) noexcept
{
    h.append(s.data(), (s.size()+1)*sizeof(CharT));
}
</pre></blockquote>

<p>
With this definition, then there is an invariant relationship between
<code>std::string</code> and string literals, no matter what hashing algorithm
is specified by the client:
</p>

<blockquote><pre>
assert(uhash&lt;&gt;{}(std::string("Hi!")) == uhash&lt;&gt;{}("Hi!"));
assert(uhash&lt;MySpecialHasher&gt;{}(std::string("Hi!")) == uhash&lt;MySpecialHasher&gt;{}("Hi!"));
</pre></blockquote>

<p>
String literals and their <code>std::basic_string</code> counterparts hash
identically!  This opens the door for the unordered container analogue of:
</p>

<blockquote><pre>
template &lt;class K&gt; iterator find(const K&amp; x);
</pre></blockquote>

<p>
to actually work for the very most important use case!
</p>

<blockquote><pre>
auto i = unordered_set_of_string.find("a string literal used to look up a std::string");
</pre></blockquote>

<p>
And without having to actually construct a <code>std::string</code>! 
<code>std::string</code> and string literals already are specified to always
compare equal for equivalent content.  And with this hashing framework, such
pairs of data are now guaranteed to hash to the same hash code.  And in an
extremely manner no less!
</p>

<b>Wait a minute.  Isn't <code>hash_append</code> the same thing as
<code>boost::hash_combine</code>?</b>

<p>No!</p>

<p>
<code>boost::hash_combine</code> is used to combine two separately computed
hash codes into one hash code.  And furthermore it hard-codes the functor to
be used for the second type.  <code>hash_append</code> accumulates state into
a <i>generic</i> hash algorithm, returning the exact same result as if the
hash algorithm had processed the entire discontiguous memory buffer as one
contiguous memory buffer.
</p>

<b>Is there a variadic version of <code>hash_append</code>?</b>

<p>
Yes, this is easily written as:
</p>

<blockquote><pre>
template &lt;class Hasher, class T0, class T1, class ...T&gt;
inline
void
hash_append (Hasher&amp; h, T0 const&amp; t0, T1 const&amp; t1, T const&amp; ...t) noexcept
{
    hash_append (h, t0);
    hash_append (h, t1, t...);
}
</pre></blockquote>

<p>
This allows <code>hash_append</code> for X (for example) to be rewritten as:
</p>

<blockquote><pre>
template &lt;class Hasher&gt;
friend void hash_append(Hasher&amp; h, X const&amp; x) noexcept
{
    using hash_defaults::hash_append;
    hash_append(h, x.data1_, x.data2_);
}
</pre></blockquote>

<b>How easily can algorithms other than FNV-1a be used?</b>

<p>
Algorithms such as
<a href="https://code.google.com/p/cityhash/">CityHash</a> are not easily
adapted to this infrastructure, because as currently coded, CityHash actually
hashes the end of the buffer first.  However
<a href="http://burtleburtle.net/bob/hash/spooky.html">SpookyHash</a>, which
is reported to have quality comparable to CityHash is trivial to incorporate:
</p>

<blockquote><pre>
#include "SpookyV2.h"

class spooky
{
    SpookyHash state_;
public: 
    spooky(std::size_t seed1 = 1, std::size_t seed2 = 2) noexcept
    {
        state_.Init(seed1, seed2);
    }

    void
    append(void const* key, std::size_t len) noexcept
    {
        state_.Update(key, len);
    }

    explicit
    operator std::size_t() noexcept
    {
        std::uint64_t h1, h2;
        state_.Final(&amp;h1, &amp;h2);
        return h1;
    }

};
</pre></blockquote>

<p>
Indeed, this has become my algorithm of choice:
</p>

<blockquote><pre>
template &lt;class T, class Hasher = spooky&gt; struct hash;
</pre></blockquote>

<b>What is involved in switching hashing algorithms?</b>

<p>
Given the class X shown above, with its complex state distributed among at
least two different contiguous chunks of memory, and potentially many more
if the container switched from <code>vector</code> to <code>deque</code> or
<code>list</code>, I can create a <code>vector</code> of hash codes with my
preferred default algorithm like so:
</p>

<blockquote><pre>
for (auto const&amp; x : vx)
    hashes.push_back(uhash&lt;&gt;{}(x));
</pre></blockquote>

<p>
If I instead wanted to specify FNV-1a, I would modify the code to:
</p>

<blockquote><pre>
for (auto const&amp; x : vx)
    hashes.push_back(uhash&lt;fnv1a&gt;{}(x));
</pre></blockquote>

<p>
This would change the hash code algorithm for every <code>vector</code>,
every <code>deque</code>, every <code>string</code>, every <code>char</code>,
every <code>int</code>, etc. for which X considered part of its hash-worthy state.
That is, hashing algorithms are controlled at the top of the data structure
chain, at the point where the client (e.g. <code>unordered_map</code>) asks for
the hash.  It is not controlled at all down at the bottom of the data structure
chain.  I.e. <code>int</code> has no clue how to hash itself.  It only knows
what state needs to be exposed to a hashing algorithm.
</p>

<p>
And there is no combining step.  The hash algorithm works identically as
if you had copied all of the various discontiguous chunks of state into
one big contiguous chunk of memory, and fed that one big chunk to the
hash algorithm.
</p>

<b>How does the quality of the resulting hash codes compare to the
<code>hash_combine</code> solution?</b>

<p>
To answer this question I have given X a randomized default constructor:
</p>

<blockquote><pre>
std::mt19937_64 eng;

X::X()
{
    std::uniform_int_distribution&lt;short&gtl; yeardata(1900, 2014);
    std::uniform_int_distribution&lt;unsigned char&gtl; monthdata(1, 12);
    std::uniform_int_distribution&lt;unsigned char&gtl; daydata(1, 28);
    std::uniform_int_distribution&lt;std::size_t&gtl; veclen(0, 100);
    std::uniform_int_distribution&lt;int&gtl; int1data(1, 10);
    std::uniform_int_distribution&lt;int&gtl; int2data(-3, 5000);
    std::get&lt;0&gtl;(date_) = yeardata(eng);
    std::get&lt;1&gtl;(date_) = monthdata(eng);
    std::get&lt;2&gtl;(date_) = daydata(eng);
    data_.resize(veclen(eng));
    for (auto&amp; p : data_)
    {
        p.first = int1data(eng);
        p.second = int2data(eng);
    }
}
</pre></blockquote>

<p>
Given this, I can easily create a great number of random X's as shown in the
loops above, and specify any hash algorithm.  I can also use
<code>std::hash</code> and "Solution 1" from the first part of this paper.
</p>

<p>
My hash function quality tester suite is quite crude.  In <code>test1</code>
I look at each 64 bit hash code as a collection of 16 hex-digits.  I expect
each hex-digit to be roughly equally represented in each hexadecimal place of
the hash code.  The test returns maximum deviation of the average, from the
expected average.
</p>

<p>
My second test is extremely simple:  It is simply the number of collisions
divided by the number of available values in the hash code.  Zero is a perfect
result.
</p>

<p>
My third test is
<a href="https://code.google.com/p/smhasher/wiki/Distribution">TestDistribution</a>
gratefully borrowed from the
<a href="https://code.google.com/p/smhasher/wiki/SMHasher">smhasher</a>
test suite.  I won't pretend to understand it.
</p>

<p>
I load up a million hash codes generated from a million randomized X's,
randomized by a default constructed <code>std::mt19937_64</code>, and feed
them to these three tests.  For each test, the smaller the result the better.
</p>

<blockquote>
<table border="1" cellpadding="5">
<caption>Test Results -- smaller is better</caption>
<tr>
<th></th> <th>test 1</th> <th>test 2</th>  <th>test 3</th> <th>total time (sec)</th>
</tr>
<tr>
<th><code>hash_combine</code></th> <td>0.394544</td> <td>1.40071e-05</td> <td>0.984445</td> <td>0.419103s</td>
</tr>
<tr>
<th>FNV-1a</th> <td>0.029664</td> <td>0</td> <td>0.0719367</td> <td>0.829794s</td>
</tr>
<tr>
<th>Spooky V2</th> <td>0.011024</td> <td>0</td> <td>0.000902987</td> <td>0.634737s</td>
</tr>
<tr>
<th>CityHash</th> <td>0.015264</td> <td>0</td> <td>0.000662453</td> <td>2.68137s</td>
</tr>
</table>
</blockquote>

<p>
The <code>hash_combine</code> solution handily wins the speed test, but with a
quality that the obsolete FNV-1a function trounces.  It does no good to get the
wrong answer faster.  In contrast, the much more sophisticated Spooky V2
algorithm has a very high quality rating.
</p>

<p>
Note in the above results that though Spooky is far more complicated than
FNV-1a, it is actually faster for the type X, due to the optimizations based
on <code>is_contiguously_hashable</code>.  Without these optimizations,
Spooky would be slower than FNV-1a.
</p>

<p>
Even though CityHash is not easily efficiently adapted to this infrastructure,
it is easy to adapt it inefficiently:  Just collect the entire buffer in a
<code>vector&lt;char&gt;</code> and hash the whole thing during the finalization
step.  I show the results of doing this just for informational purposes.
</p>

<h3>Summary</h3>

<p>
This paper presents an infrastructure that decouples types from hashing
algorithms.  This decoupling has several benefits:
</p>

<ul>
<li>Hash algorithm designers can concentrate on designing better hash
algorithms, with little worry about how these new algorithms can be
incorporated into existing code.</li>
<li>Type designers can create their hash support just once, without
worrying about what hashing algorithm should be used.</li>
<li>Clients can easily adopt most existing algorithms to this proposed
infrastructure.</li>
<li>Clients can easily very easily switch hashing algorithms used by
very complex data structures.</li>
<li>The resulting hash codes are true reflection of the original design
of the hashing algorithms, even though applied to complex data structures
spanning discontiguous memory.</li>
</ul>

<h3>Acknowledgments</h3>

<p>
This research has been generously supported by
<a href="https://www.ripplelabs.com">Ripple Labs</a>.  I would especially like to
thank my colleagues on the RippleD team.
</p>

</body>
</html>
